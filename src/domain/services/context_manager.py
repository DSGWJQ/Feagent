"""ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (Context Manager) - å¤šAgentåä½œç³»ç»Ÿçš„ä¸Šä¸‹æ–‡ç®¡ç†

ä¸šåŠ¡å®šä¹‰ï¼š
- ç®¡ç†å¤šå±‚ä¸Šä¸‹æ–‡ï¼šGlobal â†’ Session â†’ Workflow â†’ Node
- å„å±‚æœ‰ä¸åŒçš„ç”Ÿå‘½å‘¨æœŸå’Œè®¿é—®æƒé™
- æ”¯æŒä¸Šä¸‹æ–‡ç»§æ‰¿å’Œæ•°æ®æ¡¥æ¥

è®¾è®¡åŸåˆ™ï¼š
- å…¨å±€ä¸Šä¸‹æ–‡åªè¯»ï¼Œä¿æŠ¤ç³»ç»Ÿé…ç½®
- ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†ç›®æ ‡æ ˆå’Œå¯¹è¯å†å²
- å·¥ä½œæµä¸Šä¸‹æ–‡ç›¸äº’éš”ç¦»ï¼Œæ”¯æŒå¹¶å‘
- èŠ‚ç‚¹ä¸Šä¸‹æ–‡ä¸´æ—¶å­˜åœ¨ï¼Œæ‰§è¡Œå®Œé”€æ¯

å±‚çº§å…³ç³»ï¼š
    GlobalContext (åªè¯»ï¼Œæ•´ä¸ªä¼šè¯)
        â†“ ç»§æ‰¿
    SessionContext (è¯»å†™ï¼Œå•æ¬¡ä¼šè¯)
        â†“ æ´¾ç”Ÿ
    WorkflowContext (éš”ç¦»ï¼Œå•ä¸ªå·¥ä½œæµ)
        â†“ ä¸´æ—¶
    NodeContext (ä¸´æ—¶ï¼Œå•ä¸ªèŠ‚ç‚¹æ‰§è¡Œ)
"""

from collections.abc import Callable
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any

from src.domain.services.event_bus import Event

if TYPE_CHECKING:
    from src.domain.services.event_bus import EventBus
    from src.domain.services.short_term_buffer import ShortTermBuffer
    from src.domain.services.structured_dialogue_summary import StructuredDialogueSummary


@dataclass
class Goal:
    """ç›®æ ‡å®ä½“

    ç”¨äºç›®æ ‡æ ˆç®¡ç†ï¼Œæ”¯æŒåµŒå¥—ç›®æ ‡ç»“æ„ã€‚

    å±æ€§ï¼š
    - id: ç›®æ ‡å”¯ä¸€æ ‡è¯†
    - description: ç›®æ ‡æè¿°
    - parent_id: çˆ¶ç›®æ ‡IDï¼ˆç”¨äºç›®æ ‡åˆ†è§£ï¼‰
    - status: ç›®æ ‡çŠ¶æ€
    """

    id: str
    description: str
    parent_id: str | None = None
    status: str = "pending"


@dataclass
class ShortTermSaturatedEvent(Event):
    """???????? (Step 2)

    ? SessionContext ? usage_ratio ??????? 0.92?????
    ????????????????
    """

    def __init__(
        self,
        session_id: str,
        usage_ratio: float,
        total_tokens: int,
        context_limit: int,
        buffer_size: int,
        source: str = "session_context",
    ) -> None:
        super().__init__(source=source)
        self.session_id = session_id
        self.usage_ratio = usage_ratio
        self.total_tokens = total_tokens
        self.context_limit = context_limit
        self.buffer_size = buffer_size

    @property
    def event_type(self) -> str:
        """????"""
        return "short_term_saturated"


class GlobalContext:
    """å…¨å±€ä¸Šä¸‹æ–‡ - åªè¯»

    èŒè´£ï¼š
    - å­˜å‚¨ç”¨æˆ·ä¿¡æ¯å’Œåå¥½
    - å­˜å‚¨ç³»ç»Ÿé…ç½®
    - æ•´ä¸ªä¼šè¯æœŸé—´ä¸å¯ä¿®æ”¹

    ä¸ºä»€ä¹ˆè®¾è®¡ä¸ºåªè¯»ï¼Ÿ
    1. ä¿æŠ¤ç³»ç»Ÿé…ç½®ä¸è¢«Agentæ„å¤–ä¿®æ”¹
    2. ç¡®ä¿å¤šAgentå…±äº«æ—¶çš„ä¸€è‡´æ€§
    3. ä½œä¸ºæ‰€æœ‰ä¸‹å±‚ä¸Šä¸‹æ–‡çš„ç¨³å®šåŸºç¡€

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        global_ctx = GlobalContext(
            user_id="user_123",
            user_preferences={"language": "zh-CN"},
            system_config={"max_tokens": 10000}
        )
    """

    __slots__ = ("_user_id", "_user_preferences", "_system_config", "_created_at")

    def __init__(
        self,
        user_id: str,
        user_preferences: dict[str, Any] | None = None,
        system_config: dict[str, Any] | None = None,
    ):
        """åˆå§‹åŒ–å…¨å±€ä¸Šä¸‹æ–‡

        å‚æ•°ï¼š
            user_id: ç”¨æˆ·ID
            user_preferences: ç”¨æˆ·åå¥½è®¾ç½®
            system_config: ç³»ç»Ÿé…ç½®
        """
        object.__setattr__(self, "_user_id", user_id)
        object.__setattr__(self, "_user_preferences", user_preferences or {})
        object.__setattr__(self, "_system_config", system_config or {})
        object.__setattr__(self, "_created_at", datetime.now())

    @property
    def user_id(self) -> str:
        return self._user_id

    @property
    def user_preferences(self) -> dict[str, Any]:
        return self._user_preferences.copy()  # è¿”å›å‰¯æœ¬ï¼Œé˜²æ­¢ä¿®æ”¹

    @property
    def system_config(self) -> dict[str, Any]:
        return self._system_config.copy()  # è¿”å›å‰¯æœ¬ï¼Œé˜²æ­¢ä¿®æ”¹

    @property
    def created_at(self) -> datetime:
        return self._created_at

    def __setattr__(self, key: str, value: Any) -> None:
        """ç¦æ­¢ä¿®æ”¹å±æ€§"""
        raise AttributeError(f"GlobalContext is immutable, cannot modify '{key}'")


@dataclass
class SessionContext:
    """ä¼šè¯ä¸Šä¸‹æ–‡

    èŒè´£ï¼š
    - ç»§æ‰¿å…¨å±€ä¸Šä¸‹æ–‡ï¼ˆåªè¯»è®¿é—®ï¼‰
    - ç®¡ç†å¯¹è¯å†å²
    - ç®¡ç†ç›®æ ‡æ ˆï¼ˆæ”¯æŒåµŒå¥—ç›®æ ‡ï¼‰
    - è®°å½•å†³ç­–å†å²
    - è·Ÿè¸ªä¸Šä¸‹æ–‡ä½¿ç”¨æƒ…å†µï¼ˆtoken ä½¿ç”¨å’Œä½¿ç”¨ç‡ï¼‰

    ç”Ÿå‘½å‘¨æœŸï¼šå•æ¬¡ç”¨æˆ·ä¼šè¯

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        session_ctx = SessionContext(
            session_id="session_abc",
            global_context=global_ctx
        )
        session_ctx.push_goal(goal)
        session_ctx.add_message({"role": "user", "content": "..."})
        session_ctx.set_model_info("openai", "gpt-4", 8192)
        session_ctx.update_token_usage(prompt_tokens=100, completion_tokens=50)
    """

    session_id: str
    global_context: GlobalContext

    # å¯¹è¯å†å²
    conversation_history: list[dict[str, Any]] = field(default_factory=list)

    # ç›®æ ‡æ ˆ - æ”¯æŒåµŒå¥—ç›®æ ‡
    goal_stack: list[Goal] = field(default_factory=list)

    # å†³ç­–å†å² - ç”¨äºå®¡è®¡
    decision_history: list[dict[str, Any]] = field(default_factory=list)

    # æ‘˜è¦ç¼“å­˜
    conversation_summary: str | None = None

    # Token ä½¿ç”¨è·Ÿè¸ªï¼ˆStep 1: æ¨¡å‹ä¸Šä¸‹æ–‡èƒ½åŠ›ç¡®è®¤ï¼‰
    total_prompt_tokens: int = 0
    total_completion_tokens: int = 0
    total_tokens: int = 0
    usage_ratio: float = 0.0

    # æ¨¡å‹ä¿¡æ¯
    llm_provider: str | None = None
    llm_model: str | None = None
    context_limit: int = 0

    # Step 2: çŸ­æœŸè®°å¿†ç¼“å†²åŒº
    short_term_buffer: list["ShortTermBuffer"] = field(default_factory=list)
    is_saturated: bool = False
    saturation_threshold: float = 0.92
    _event_bus: "EventBus | None" = field(default=None, repr=False)

    # Step 3: ä¼šè¯å†»ç»“ä¸å¤‡ä»½
    _is_frozen: bool = field(default=False, repr=False)
    _backup: dict[str, Any] | None = field(default=None, repr=False)

    def add_message(self, message: dict[str, Any]) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²

        å‚æ•°ï¼š
            message: æ¶ˆæ¯å­—å…¸ï¼ŒåŒ…å«roleå’Œcontent
        """
        self.conversation_history.append(message)

    def push_goal(self, goal: Goal) -> None:
        """å°†ç›®æ ‡å‹å…¥æ ˆ

        å‚æ•°ï¼š
            goal: ç›®æ ‡å®ä½“
        """
        self.goal_stack.append(goal)

    def pop_goal(self) -> Goal | None:
        """ä»æ ˆé¡¶å¼¹å‡ºç›®æ ‡

        è¿”å›ï¼š
            å¼¹å‡ºçš„ç›®æ ‡ï¼Œå¦‚æœæ ˆä¸ºç©ºè¿”å›None
        """
        if self.goal_stack:
            return self.goal_stack.pop()
        return None

    def current_goal(self) -> Goal | None:
        """è·å–å½“å‰ç›®æ ‡ï¼ˆæ ˆé¡¶ï¼‰

        è¿”å›ï¼š
            æ ˆé¡¶ç›®æ ‡ï¼Œå¦‚æœæ ˆä¸ºç©ºè¿”å›None
        """
        if self.goal_stack:
            return self.goal_stack[-1]
        return None

    def add_decision(self, decision: dict[str, Any]) -> None:
        """è®°å½•å†³ç­–

        å‚æ•°ï¼š
            decision: å†³ç­–å­—å…¸
        """
        self.decision_history.append(decision)

    def set_model_info(self, provider: str, model: str, context_limit: int) -> None:
        """è®¾ç½®æ¨¡å‹ä¿¡æ¯

        å‚æ•°ï¼š
            provider: LLM æä¾›å•†åç§°
            model: æ¨¡å‹åç§°
            context_limit: ä¸Šä¸‹æ–‡çª—å£å¤§å°
        """
        self.llm_provider = provider
        self.llm_model = model
        self.context_limit = context_limit

        # é‡æ–°è®¡ç®—ä½¿ç”¨ç‡
        self._recalculate_usage_ratio()

    def update_token_usage(self, prompt_tokens: int, completion_tokens: int) -> None:
        """æ›´æ–° token ä½¿ç”¨æƒ…å†µ

        å‚æ•°ï¼š
            prompt_tokens: æœ¬è½®ä½¿ç”¨çš„ prompt tokens
            completion_tokens: æœ¬è½®ä½¿ç”¨çš„ completion tokens
        """
        self.total_prompt_tokens += prompt_tokens
        self.total_completion_tokens += completion_tokens
        self.total_tokens = self.total_prompt_tokens + self.total_completion_tokens

        # é‡æ–°è®¡ç®—ä½¿ç”¨ç‡
        self._recalculate_usage_ratio()

    def _recalculate_usage_ratio(self) -> None:
        """é‡æ–°è®¡ç®—ä½¿ç”¨ç‡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        if self.context_limit > 0:
            self.usage_ratio = self.total_tokens / self.context_limit
        else:
            self.usage_ratio = 0.0

    def get_usage_ratio(self) -> float:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡

        è¿”å›ï¼š
            ä½¿ç”¨ç‡ï¼ˆ0-1 ä¹‹é—´ï¼Œè¶…è¿‡ 1 è¡¨ç¤ºè¶…é™ï¼‰
        """
        return self.usage_ratio

    def is_approaching_limit(self, threshold: float = 0.8) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ¥è¿‘ä¸Šä¸‹æ–‡é™åˆ¶

        å‚æ•°ï¼š
            threshold: é˜ˆå€¼ï¼ˆé»˜è®¤ 0.8ï¼Œå³ 80%ï¼‰

        è¿”å›ï¼š
            æ˜¯å¦æ¥è¿‘é™åˆ¶
        """
        return self.usage_ratio >= threshold

    def get_remaining_tokens(self) -> int:
        """è·å–å‰©ä½™å¯ç”¨ token æ•°

        è¿”å›ï¼š
            å‰©ä½™ token æ•°ï¼ˆæœ€å°ä¸º 0ï¼‰
        """
        remaining = self.context_limit - self.total_tokens
        return max(0, remaining)

    def get_token_usage_summary(self) -> dict[str, Any]:
        """è·å– token ä½¿ç”¨æ‘˜è¦

        è¿”å›ï¼š
            åŒ…å«æ‰€æœ‰ token ä½¿ç”¨ä¿¡æ¯çš„å­—å…¸
        """
        return {
            "total_prompt_tokens": self.total_prompt_tokens,
            "total_completion_tokens": self.total_completion_tokens,
            "total_tokens": self.total_tokens,
            "usage_ratio": self.usage_ratio,
            "context_limit": self.context_limit,
            "remaining_tokens": self.get_remaining_tokens(),
            "llm_provider": self.llm_provider,
            "llm_model": self.llm_model,
        }

    def reset_token_usage(self) -> None:
        """é‡ç½® token ä½¿ç”¨è®¡æ•°å™¨"""
        self.total_prompt_tokens = 0
        self.total_completion_tokens = 0
        self.total_tokens = 0
        self.usage_ratio = 0.0

    def set_event_bus(self, event_bus: "EventBus") -> None:
        """è®¾ç½®äº‹ä»¶æ€»çº¿ï¼ˆStep 2ï¼‰

        å‚æ•°ï¼š
            event_bus: EventBus å®ä¾‹
        """
        self._event_bus = event_bus

    def check_saturation(self, threshold: float | None = None) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é¥±å’Œé˜ˆå€¼ï¼ˆStep 2ï¼‰

        å‚æ•°ï¼š
            threshold: è‡ªå®šä¹‰é˜ˆå€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ saturation_thresholdï¼‰

        è¿”å›ï¼š
            æ˜¯å¦è¾¾åˆ°é¥±å’Œé˜ˆå€¼
        """
        if threshold is None:
            threshold = self.saturation_threshold

        return self.usage_ratio >= threshold

    def _trigger_saturation_event(self) -> None:
        """è§¦å‘é¥±å’Œäº‹ä»¶ï¼ˆStep 2ï¼Œå†…éƒ¨æ–¹æ³•ï¼‰

        å‘å¸ƒ ShortTermSaturatedEvent å¹¶è®¾ç½® is_saturated æ ‡å¿—ã€‚
        """
        import asyncio
        import logging

        logger = logging.getLogger(__name__)

        # è®¾ç½®é¥±å’Œæ ‡å¿—ï¼ˆé˜²æ­¢é‡å¤è§¦å‘ï¼‰
        self.is_saturated = True

        # å‘å¸ƒäº‹ä»¶
        if self._event_bus:
            event = ShortTermSaturatedEvent(
                source="session_context",
                session_id=self.session_id,
                usage_ratio=self.usage_ratio,
                total_tokens=self.total_tokens,
                context_limit=self.context_limit,
                buffer_size=len(self.short_term_buffer),
            )

            # å¼‚æ­¥å‘å¸ƒäº‹ä»¶
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.create_task(self._event_bus.publish(event))
                else:
                    loop.run_until_complete(self._event_bus.publish(event))
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                asyncio.run(self._event_bus.publish(event))

            logger.warning(
                f"ğŸ”´ Short-term memory saturated! "
                f"Session: {self.session_id}, "
                f"Usage: {self.usage_ratio:.1%}, "
                f"Buffer size: {len(self.short_term_buffer)} turns"
            )

    def reset_saturation(self) -> None:
        """é‡ç½®é¥±å’ŒçŠ¶æ€ï¼ˆStep 2ï¼‰

        æ¸…é™¤ is_saturated æ ‡å¿—ï¼Œå…è®¸å†æ¬¡è§¦å‘é¥±å’Œäº‹ä»¶ã€‚
        é€šå¸¸åœ¨ä¸Šä¸‹æ–‡å‹ç¼©å®Œæˆåè°ƒç”¨ã€‚
        """
        self.is_saturated = False

    def freeze(self) -> None:
        """å†»ç»“ä¼šè¯ï¼ˆStep 3ï¼‰

        å†»ç»“ä¼šè¯åï¼Œä¸å…è®¸ä¿®æ”¹ä¼šè¯çŠ¶æ€ã€‚
        ç”¨äºåœ¨å‹ç¼©è¿‡ç¨‹ä¸­é˜²æ­¢å¹¶å‘ä¿®æ”¹ã€‚
        """
        self._is_frozen = True

    def unfreeze(self) -> None:
        """è§£å†»ä¼šè¯ï¼ˆStep 3ï¼‰

        è§£å†»ä¼šè¯ï¼Œå…è®¸ä¿®æ”¹ä¼šè¯çŠ¶æ€ã€‚
        """
        self._is_frozen = False

    def is_frozen(self) -> bool:
        """åˆ¤æ–­ä¼šè¯æ˜¯å¦è¢«å†»ç»“ï¼ˆStep 3ï¼‰

        è¿”å›ï¼š
            æ˜¯å¦è¢«å†»ç»“
        """
        return self._is_frozen

    def create_backup(self) -> dict[str, Any]:
        """åˆ›å»ºä¼šè¯å¤‡ä»½ï¼ˆStep 3ï¼‰

        å¤‡ä»½å½“å‰ä¼šè¯çŠ¶æ€ï¼Œç”¨äºå‹ç¼©å¤±è´¥æ—¶å›æ»šã€‚

        è¿”å›ï¼š
            åŒ…å«ä¼šè¯çŠ¶æ€çš„å¤‡ä»½å­—å…¸
        """

        backup = {
            "total_prompt_tokens": self.total_prompt_tokens,
            "total_completion_tokens": self.total_completion_tokens,
            "total_tokens": self.total_tokens,
            "usage_ratio": self.usage_ratio,
            "short_term_buffer": [buffer.to_dict() for buffer in self.short_term_buffer],
            "conversation_summary": self.conversation_summary,
            "is_saturated": self.is_saturated,
        }

        self._backup = backup
        return backup

    def restore_from_backup(self, backup: dict[str, Any]) -> None:
        """ä»å¤‡ä»½æ¢å¤ä¼šè¯çŠ¶æ€ï¼ˆStep 3ï¼‰

        å‚æ•°ï¼š
            backup: å¤‡ä»½å­—å…¸
        """
        from src.domain.services.short_term_buffer import ShortTermBuffer

        self.total_prompt_tokens = backup["total_prompt_tokens"]
        self.total_completion_tokens = backup["total_completion_tokens"]
        self.total_tokens = backup["total_tokens"]
        self.usage_ratio = backup["usage_ratio"]
        self.short_term_buffer = [
            ShortTermBuffer.from_dict(data) for data in backup["short_term_buffer"]
        ]
        self.conversation_summary = backup["conversation_summary"]
        self.is_saturated = backup["is_saturated"]

    def compress_buffer_with_summary(
        self, summary: "StructuredDialogueSummary", keep_recent_turns: int = 2
    ) -> None:
        """ç”¨æ‘˜è¦å‹ç¼© bufferï¼ˆStep 3ï¼‰

        å°†æ—§çš„å¯¹è¯è½®æ¬¡å‹ç¼©ä¸ºæ‘˜è¦ï¼Œåªä¿ç•™æœ€è¿‘çš„ N è½®ã€‚

        å‚æ•°ï¼š
            summary: ç»“æ„åŒ–å¯¹è¯æ‘˜è¦
            keep_recent_turns: ä¿ç•™æœ€è¿‘çš„è½®æ¬¡æ•°ï¼ˆé»˜è®¤ 2ï¼‰
        """
        # ä¿ç•™æœ€è¿‘çš„ N è½®
        if len(self.short_term_buffer) > keep_recent_turns:
            self.short_term_buffer = self.short_term_buffer[-keep_recent_turns:]

        # å­˜å‚¨æ‘˜è¦ï¼ˆè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ï¼‰
        self.conversation_summary = summary.to_text()

    def add_turn(self, buffer: "ShortTermBuffer") -> None:
        """æ·»åŠ å¯¹è¯è½®æ¬¡åˆ°çŸ­æœŸç¼“å†²åŒºï¼ˆStep 2ï¼‰

        å‚æ•°ï¼š
            buffer: ShortTermBuffer å®ä¾‹

        è¯´æ˜ï¼š
            - æ·»åŠ è½®æ¬¡åˆ°ç¼“å†²åŒº
            - æ£€æµ‹æ˜¯å¦è¾¾åˆ°é¥±å’Œé˜ˆå€¼
            - å¦‚æœè¾¾åˆ°é˜ˆå€¼ä¸”æœªé¥±å’Œï¼Œå‘å¸ƒ ShortTermSaturatedEvent

        å¼‚å¸¸ï¼š
            RuntimeError: å¦‚æœä¼šè¯è¢«å†»ç»“
        """
        # Step 3: æ£€æŸ¥ä¼šè¯æ˜¯å¦è¢«å†»ç»“
        if self._is_frozen:
            raise RuntimeError("Cannot add turn to frozen session (ä¼šè¯å·²å†»ç»“ï¼Œæ— æ³•æ·»åŠ è½®æ¬¡)")

        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.short_term_buffer.append(buffer)

        # æ£€æµ‹é¥±å’Œ
        if not self.is_saturated and self.check_saturation():
            self._trigger_saturation_event()


@dataclass
class WorkflowContext:
    """å·¥ä½œæµä¸Šä¸‹æ–‡

    èŒè´£ï¼š
    - å¼•ç”¨ä¼šè¯ä¸Šä¸‹æ–‡ï¼ˆåªè¯»ï¼‰
    - å­˜å‚¨èŠ‚ç‚¹è¾“å‡ºæ•°æ®
    - ç®¡ç†å·¥ä½œæµå˜é‡
    - è®°å½•æ‰§è¡Œå†å²

    è®¾è®¡ç‰¹ç‚¹ï¼š
    - æ¯ä¸ªå·¥ä½œæµæœ‰ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡ï¼Œç›¸äº’éš”ç¦»
    - æ”¯æŒå¹¶å‘æ‰§è¡Œå¤šä¸ªå·¥ä½œæµ
    - èŠ‚ç‚¹é—´é€šè¿‡æ­¤ä¸Šä¸‹æ–‡ä¼ é€’æ•°æ®

    ç”Ÿå‘½å‘¨æœŸï¼šå•ä¸ªå·¥ä½œæµæ‰§è¡Œ

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        workflow_ctx = WorkflowContext(
            workflow_id="workflow_xyz",
            session_context=session_ctx
        )
        workflow_ctx.set_node_output("node_1", {"result": "success"})
        output = workflow_ctx.get_node_output("node_1", "result")
    """

    workflow_id: str
    session_context: SessionContext

    # èŠ‚ç‚¹è¾“å‡ºæ•°æ®: node_id -> outputs
    node_data: dict[str, dict[str, Any]] = field(default_factory=dict)

    # å·¥ä½œæµå˜é‡
    variables: dict[str, Any] = field(default_factory=dict)

    # æ‰§è¡Œå†å²
    execution_history: list[dict[str, Any]] = field(default_factory=list)

    def set_node_output(self, node_id: str, outputs: dict[str, Any]) -> None:
        """è®¾ç½®èŠ‚ç‚¹è¾“å‡º

        å‚æ•°ï¼š
            node_id: èŠ‚ç‚¹ID
            outputs: è¾“å‡ºæ•°æ®å­—å…¸
        """
        self.node_data[node_id] = outputs

    def get_node_output(self, node_id: str, key: str | None = None) -> Any:
        """è·å–èŠ‚ç‚¹è¾“å‡º

        å‚æ•°ï¼š
            node_id: èŠ‚ç‚¹ID
            key: å¯é€‰ï¼Œè·å–ç‰¹å®šçš„è¾“å‡ºkey

        è¿”å›ï¼š
            å¦‚æœæŒ‡å®škeyï¼Œè¿”å›è¯¥keyçš„å€¼
            å¦åˆ™è¿”å›æ•´ä¸ªè¾“å‡ºå­—å…¸
        """
        outputs = self.node_data.get(node_id, {})
        if key is not None:
            return outputs.get(key)
        return outputs

    def set_variable(self, name: str, value: Any) -> None:
        """è®¾ç½®å·¥ä½œæµå˜é‡

        å‚æ•°ï¼š
            name: å˜é‡å
            value: å˜é‡å€¼
        """
        self.variables[name] = value

    def get_variable(self, name: str, default: Any = None) -> Any:
        """è·å–å·¥ä½œæµå˜é‡

        å‚æ•°ï¼š
            name: å˜é‡å
            default: é»˜è®¤å€¼ï¼ˆå˜é‡ä¸å­˜åœ¨æ—¶è¿”å›ï¼‰

        è¿”å›ï¼š
            å˜é‡å€¼ï¼Œæˆ–é»˜è®¤å€¼
        """
        return self.variables.get(name, default)


@dataclass
class NodeContext:
    """èŠ‚ç‚¹ä¸Šä¸‹æ–‡

    èŒè´£ï¼š
    - å¼•ç”¨å·¥ä½œæµä¸Šä¸‹æ–‡
    - å­˜å‚¨èŠ‚ç‚¹è¾“å…¥
    - è·Ÿè¸ªæ‰§è¡ŒçŠ¶æ€
    - å­˜å‚¨èŠ‚ç‚¹è¾“å‡º

    ç”Ÿå‘½å‘¨æœŸï¼šå•ä¸ªèŠ‚ç‚¹æ‰§è¡Œï¼ˆæœ€çŸ­ï¼‰

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        node_ctx = NodeContext(
            node_id="node_llm_1",
            workflow_context=workflow_ctx,
            inputs={"prompt": "åˆ†ææ•°æ®"}
        )
        node_ctx.set_state("running")
        node_ctx.set_output("result", "åˆ†æå®Œæˆ")
        node_ctx.set_state("completed")
    """

    node_id: str
    workflow_context: WorkflowContext

    # èŠ‚ç‚¹è¾“å…¥
    inputs: dict[str, Any] = field(default_factory=dict)

    # èŠ‚ç‚¹è¾“å‡º
    outputs: dict[str, Any] = field(default_factory=dict)

    # æ‰§è¡ŒçŠ¶æ€: pending | running | completed | failed
    execution_state: str = "pending"

    # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    error: str | None = None

    # æ—¶é—´æˆ³
    started_at: datetime | None = None
    completed_at: datetime | None = None

    def set_state(self, state: str) -> None:
        """è®¾ç½®æ‰§è¡ŒçŠ¶æ€

        å‚æ•°ï¼š
            state: çŠ¶æ€å€¼ (pending/running/completed/failed)
        """
        self.execution_state = state

        if state == "running":
            self.started_at = datetime.now()
        elif state in ("completed", "failed"):
            self.completed_at = datetime.now()

    def set_output(self, key: str, value: Any) -> None:
        """è®¾ç½®è¾“å‡ºå€¼

        å‚æ•°ï¼š
            key: è¾“å‡ºkey
            value: è¾“å‡ºå€¼
        """
        self.outputs[key] = value


class ContextBridge:
    """ä¸Šä¸‹æ–‡æ¡¥æ¥å™¨

    èŒè´£ï¼š
    - åœ¨å·¥ä½œæµä¸Šä¸‹æ–‡ä¹‹é—´ä¼ é€’æ•°æ®
    - æ”¯æŒé€‰æ‹©æ€§ä¼ é€’ï¼ˆåªä¼ é€’éœ€è¦çš„æ•°æ®ï¼‰
    - æ”¯æŒæ•°æ®æ‘˜è¦ï¼ˆå‡å°‘tokenæ¶ˆè€—ï¼‰

    ä½¿ç”¨åœºæ™¯ï¼š
    - ç›®æ ‡åˆ†è§£åï¼Œå­å·¥ä½œæµä¹‹é—´ä¼ é€’ç»“æœ
    - å·¥ä½œæµå®Œæˆåï¼Œç»“æœä¼ é€’ç»™ä¸‹ä¸€ä¸ªå·¥ä½œæµ

    ä½¿ç”¨ç¤ºä¾‹ï¼š
        bridge = ContextBridge()
        bridge.transfer(source_workflow, target_workflow, keys=["result"])
    """

    def transfer(
        self, source: WorkflowContext, target: WorkflowContext, keys: list[str] | None = None
    ) -> dict[str, Any]:
        """ä¼ é€’æ•°æ®

        å‚æ•°ï¼š
            source: æºå·¥ä½œæµä¸Šä¸‹æ–‡
            target: ç›®æ ‡å·¥ä½œæµä¸Šä¸‹æ–‡
            keys: è¦ä¼ é€’çš„keyåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºä¼ é€’æ‰€æœ‰

        è¿”å›ï¼š
            ä¼ é€’çš„æ•°æ®
        """
        # æ”¶é›†è¦ä¼ é€’çš„æ•°æ®
        transferred_data = {}

        # ä»èŠ‚ç‚¹è¾“å‡ºæ”¶é›†
        for _node_id, outputs in source.node_data.items():
            for key, value in outputs.items():
                if keys is None or key in keys:
                    transferred_data[key] = value

        # ä»å˜é‡æ”¶é›†
        for var_name, var_value in source.variables.items():
            if keys is None or var_name in keys:
                transferred_data[var_name] = var_value

        # æ³¨å…¥åˆ°ç›®æ ‡ä¸Šä¸‹æ–‡
        target.set_variable("__transferred__", transferred_data)

        return transferred_data

    def transfer_with_summary(
        self,
        source: WorkflowContext,
        target: WorkflowContext,
        summary_fn: Callable[[Any], dict[str, Any]],
    ) -> dict[str, Any]:
        """ä¼ é€’æ•°æ®å¹¶æ‘˜è¦

        å‚æ•°ï¼š
            source: æºå·¥ä½œæµä¸Šä¸‹æ–‡
            target: ç›®æ ‡å·¥ä½œæµä¸Šä¸‹æ–‡
            summary_fn: æ‘˜è¦å‡½æ•°ï¼Œæ¥æ”¶åŸå§‹æ•°æ®ï¼Œè¿”å›æ‘˜è¦

        è¿”å›ï¼š
            æ‘˜è¦åçš„æ•°æ®
        """
        # æ”¶é›†æ‰€æœ‰æ•°æ®
        all_data = []
        for _node_id, outputs in source.node_data.items():
            all_data.extend(outputs.values())

        for var_value in source.variables.values():
            all_data.append(var_value)

        # åº”ç”¨æ‘˜è¦å‡½æ•°
        if all_data:
            # å¦‚æœæ•°æ®æ˜¯åˆ—è¡¨ï¼Œå±•å¼€ä¼ é€’
            if len(all_data) == 1:
                summarized = summary_fn(all_data[0])
            else:
                summarized = summary_fn(all_data)
        else:
            summarized = {}

        # æ³¨å…¥åˆ°ç›®æ ‡ä¸Šä¸‹æ–‡
        target.set_variable("__transferred__", summarized)

        return summarized


# å¯¼å‡º
__all__ = [
    "Goal",
    "GlobalContext",
    "SessionContext",
    "WorkflowContext",
    "NodeContext",
    "ContextBridge",
]
