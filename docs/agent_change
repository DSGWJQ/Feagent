Agent 迭代文档
§Agent v2消息处理器重构技术方案
§1. 重构背景与目标
§1.1 背景
现有的v1 AgentMessageHandler类实现了复杂任务的拆分、执行和汇总流程，但代码臃肿，职责不够清晰，且存在重复代码，不利于维护和扩展。
§1.2 目标
◦ 实现关注点分离，遵循单一职责原则
◦ 基于事件驱动架构重构工作流
◦ 消除重复代码，提高可维护性
◦ 规范状态转换，增强可扩展性
§2. 现有系统问题分析
§2.1 系统缺陷
◦ 代码耦合度高，单个类承担多种职责
◦ 流程控制集中在一处，难以扩展新的处理逻辑
◦ 重复代码多，如消息创建、请求构建等
◦ 错误处理分散，不够统一
§2.2 架构缺陷
◦ 状态转换隐式进行，不够清晰
◦ 异步执行流程不够清晰，难以跟踪和调试
◦ 子任务创建和执行逻辑混合，职责不清
§3. 重构设计方案
§3.1 整体架构
采用基于状态和事件的设计模式，将工作流分解为多个独立的处理器：
1
┌─────────────────┐       ┌───────────────────┐
2
│ AgentMessageHandler│─────▶│  事件总线(AgentEventBus) │
3
└─────────────────┘       └──────────┬────────┘
4
│
5
▼
6
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
7
│ TaskSplitHandler │◀───┤ 工作流状态转换  ├───▶│TaskExecutionHandler│
8
└─────────────────┘    └─────────────────┘    └─────────┬───────┘
9
│
10
▼
11
┌─────────────────┐
12
│ SummarizeHandler │
13
└─────────────────┘
§3.2 核心组件
AbstractAgentHandler：处理器抽象基类，提取公共能力
AgentEventBus：事件分发组件，负责注册和触发事件处理
AgentWorkflowContext：工作流上下文，包含状态、任务和结果
AgentWorkflowState：工作流状态枚举，定义明确的状态转换
§3.3 工作流状态定义
1
INITIALIZED ──▶ TASK_SPLITTING ──▶ TASK_SPLIT_COMPLETED ──▶ TASK_EXECUTING
2
│
3
▼
4
COMPLETED ◀── SUMMARIZING ◀── TASK_EXECUTED
§4. 详细设计
§4.1 AbstractAgentHandler抽象基类设计
1
public abstract class AbstractAgentHandler implements AgentEventHandler {
2
3
// 共享依赖
4
protected final LLMServiceFactory llmServiceFactory;
5
protected final TaskManager taskManager;
6
protected final ConversationDomainService conversationDomainService;
7
protected final ContextDomainService contextDomainService;
8
9
// 模板方法模式
10
@Override
11
public final void handle(AgentWorkflowEvent event) {
12
if (!shouldHandle(event)) {
13
return;
14
}
15
16
AgentWorkflowContext<?> context = event.getContext();
17
transitionToNextState(context);
18
processEvent(context);
19
}
20
21
// 抽象方法，子类实现
22
protected abstract boolean shouldHandle(AgentWorkflowEvent event);
23
protected abstract void transitionToNextState(AgentWorkflowContext<?> context);
24
protected abstract <T> void processEvent(AgentWorkflowContext<?> context);
25
26
// 公共工具方法
27
protected <T> MessageEntity createMessageEntity(...) { ... }
28
protected <T> StreamingChatLanguageModel getStreamingClient(...) { ... }
29
protected <T> ChatRequest buildChatRequest(...) { ... }
30
}
§4.2 事件处理器实现
§4.2.1 TaskSplitHandler
负责任务拆分，将复杂任务分解为子任务列表。
1
@Component
2
public class TaskSplitHandler extends AbstractAgentHandler {
3
// 特有依赖
4
private final PromptTemplates promptTemplates;
5
6
@Override
7
protected boolean shouldHandle(AgentWorkflowEvent event) {
8
return event.getToState() == AgentWorkflowState.TASK_SPLITTING;
9
}
10
11
@Override
12
protected void processEvent(AgentWorkflowContext<?> context) {
13
// 执行任务拆分
14
// 创建子任务
15
// 保存消息到上下文
16
// 状态转换
17
}
18
}

§4.2.2 TaskExecutionHandler
负责子任务的执行，包括工具调用处理。
1
@Component
2
public class TaskExecutionHandler extends AbstractAgentHandler {
3
// 特有依赖
4
private final AgentToolManager toolManager;
5
6
@Override
7
protected boolean shouldHandle(AgentWorkflowEvent event) {
8
return event.getToState() == AgentWorkflowState.TASK_SPLIT_COMPLETED;
9
}
10
11
@Override
12
protected void processEvent(AgentWorkflowContext<?> context) {
13
// 循环执行子任务
14
// 处理工具调用
15
// 状态转换
16
}
17
}

§4.2.3 SummarizeHandler
负责汇总任务结果，生成最终回复。
1
@Component
2
public class SummarizeHandler extends AbstractAgentHandler {
3
// 特有依赖
4
private final PromptTemplates promptTemplates;
5
6
@Override
7
protected boolean shouldHandle(AgentWorkflowEvent event) {
8
return event.getToState() == AgentWorkflowState.TASK_EXECUTED;
9
}
10
11
@Override
12
protected void processEvent(AgentWorkflowContext<?> context) {
13
// 汇总子任务结果
14
// 生成总结
15
// 状态转换
16
}
17
}

§4.3 AgentMessageHandler重构
1
@Component(value = "agentMessageHandler")
2
public class AgentMessageHandler extends AbstractMessageHandler {
3
// 构造函数注入依赖
4
public AgentMessageHandler(
5
// 注入依赖项
6
TaskSplitHandler taskSplitHandler,
7
TaskExecutionHandler taskExecutionHandler,
8
SummarizeHandler summarizeHandler) {
9
10
// 构造函数中直接注册事件处理器
11
AgentEventBus.register(AgentWorkflowState.TASK_SPLITTING, taskSplitHandler);
12
AgentEventBus.register(AgentWorkflowState.TASK_SPLIT_COMPLETED, taskExecutionHandler);
13
AgentEventBus.register(AgentWorkflowState.TASK_EXECUTED, summarizeHandler);
14
}
15
16
@Override
17
public <T> T chat(ChatContext chatContext, MessageTransport<T> messageTransport) {
18
// 创建工作流上下文
19
// 触发初始状态转换
20
// 立即返回连接
21
}
22
}

§5. 优势与改进
§5.1 架构优势
◦ 松耦合：各组件通过事件关联，相互独立
◦ 可扩展性：新增处理逻辑只需添加新的处理器和状态
◦ 代码复用：通过抽象基类消除重复代码
◦ 职责清晰：每个处理器专注于单一职责
§5.2 技术优势
◦ 状态明确：显式定义状态转换，便于调试和追踪
◦ 错误处理统一：集中在各处理器中，便于监控
◦ 依赖注入规范：通过构造函数注入，符合Spring最佳实践
◦ 维护性提升：代码组织更合理，便于理解和修改
§5.3 业务优势
◦ 流程可视：状态变化更直观，业务流程更清晰
◦ 执行灵活：支持未来添加并行执行、重试机制等
◦ 结果一致：保持原有功能不变，同时提高可靠性
§6. 实现注意事项
各处理器需正确保存消息和更新上下文
确保异常处理涵盖所有场景
构造函数依赖注入需注意初始化顺序
避免使用ApplicationContextHolder等静态访问方式
§Agent v3消息处理器重构技术方案
§一、演进概述
AgentX系统的Agent模式经历了从复杂的事件驱动架构向简洁高效的循环执行模式演进，这种转变优化了用户体验，提高了系统的响应性和可维护性。
特性
原始Agent模式
新Agent模式
架构基础
事件驱动+状态机
简单循环+大模型自主决策
用户交互
有限干预，批处理式
全程可干预，对话式
任务执行
严格的任务拆分-执行-汇总
大模型自主决策执行流程
系统复杂度
高（多事件、多状态、多处理器）
低（单一循环、清晰流程）
§二、原始Agent模式详解
§设计理念
原始Agent模式采用严格的工作流程控制，将复杂任务拆分为子任务后依次执行，强调过程的结构化和可管理性。
§架构特点
状态驱动：使用AgentWorkflowState枚举定义多个工作流状态，如分析、拆分、执行等
事件系统：通过AgentEventBus处理状态转换和事件分发
多处理器模式：针对不同阶段使用专门的处理器（AnalyserMessageHandler、TaskSplitHandler等）
严格的任务管理：使用TaskManager创建和管理父任务和子任务
§执行流程
分析用户输入是问答还是任务
检查信息完整性，可能多轮交互获取信息
将任务拆分为多个子任务
依次执行子任务，无法中途干预
汇总子任务结果，生成最终回答
§优缺点
优点：
◦ 结构清晰，阶段分明
◦ 任务进度可视化
◦ 结果组织严谨
缺点：
◦ 交互体验割裂
◦ 系统复杂难维护
◦ 用户无法干预执行过程
◦ 缺乏灵活性应对复杂场景
§三、新Agent模式详解
§设计理念
新Agent模式强调自然对话和灵活响应，让大模型自主决策执行流程，用户可随时干预，整个过程呈现为连续对话而非结构化任务列表。
§架构特点
循环执行：使用简单while循环控制执行流程
大模型自主决策：由大模型决定是否调用工具及调用方式
实时交互：工具调用和思考过程对用户可见
简化设计：去除事件总线、状态机和复杂处理器链
§执行流程
判断是否为Agent模式
分析用户输入是否需要作为任务处理
进入最多30次的循环执行：
获取大模型响应
分析是否需要调用工具
执行工具调用并获取结果
将结果反馈给大模型继续判断
用户可随时中断并输入新指令
§优缺点
优点：
◦ 用户体验流畅自然
◦ 系统简单易维护
◦ 灵活应对各种场景
◦ 用户可随时干预
◦ 透明的执行过程
缺点：
◦ 工具调用顺序不可预测
◦ 可能存在循环调用风险(已通过最大循环次数限制)
◦ 对大模型能力要求更高
§四、技术实现对比
技术组件
原始Agent模式
新Agent模式
核心处理类
AgentMessageHandler + 多个状态处理器
单一Agent处理类
状态管理
AgentWorkflowState枚举 + 状态转换
简单标志位
事件机制
AgentEventBus + 事件处理器注册
无事件系统
任务管理
TaskManager + 父子任务关系
无显式任务实体
工具调用
在任务执行阶段固定调用
大模型自主决定调用时机
上下文传递
AgentWorkflowContext复杂上下文
简单消息历史列表
§五、交互模式对比
§原始Agent模式交互
1
用户: 帮我规划一次旅行
2
3
系统: [拆分任务]
4
任务1: 确定旅行目的地
5
任务2: 规划行程时间和预算
6
任务3: 设计旅行路线
7
...
8
9
系统: [执行任务1]
10
根据您的需求，我推荐以下目的地...
11
12
系统: [执行任务2]
13
考虑到旅行季节，建议安排...
14
15
系统: [最终汇总]
16
为您规划的旅行方案如下...
§新Agent模式交互
1
用户: 帮我规划一次旅行
2
3
系统: 我可以帮您规划旅行。请问您有特定的目的地或时间安排吗？
4
5
用户: 我想去日本，大约7天，预算15000元
6
7
系统: 好的，我会为您规划日本7天的行程。
8
[思考] 我需要查询一下日本的热门景点和交通情况...
9
[调用搜索工具] 查询"日本7天旅游路线推荐"
10
[工具结果] 返回东京-京都-大阪经典路线信息...
11
12
根据搜索结果，我推荐以下行程:
13
第1天: 到达东京，游览浅草寺和东京塔...
14
...
15
16
用户: [中途打断] 我对温泉更感兴趣
17
18
系统: [调整响应] 明白了，我会调整行程加入更多温泉体验...
19
[调用搜索工具] 查询"日本最佳温泉胜地"
§六、演进启示
简单胜于复杂：过度工程化不一定带来更好体验
以用户为中心：自然对话式交互优于结构化任务执行
信任大模型能力：让大模型自主决策而非严格控制其行为
保持灵活性：允许随时中断和调整是良好用户体验的核心
实时反馈：让执行过程透明可见增强用户信任和控制感
新的Agent模式设计充分体现了"大模型时代"的技术理念：信任AI的判断力，简化系统设计，提供自然流畅的交互体验。这种设计更符合用户期望，也更容易实现和维护。
§Agent v4消息处理器重构技术方案
§背景
在此之前涉及到的判断消息，任务缺少信息行为，是完全可以通过系统提示词进行，关于任务的拆分也可以作为系统提示词。因此整个架构 = 大模型 + 工具 + 系统提示词 + 自主循环调用
构建历史消息
1
protected void buildHistoryMessage(ChatContext chatContext, MessageWindowChatMemory memory) {
2
String summary = chatContext.getContextEntity().getSummary();
3
if (StringUtils.isNotEmpty(summary)) {
4
// 添加为AI消息，但明确标识这是摘要
5
memory.add(new AiMessage(AgentPromptTemplates.getSummaryPrefix() + summary));
6
}
7
// 这里只能设置一条，否则会覆盖，因此需要拼接
8
memory.add(new SystemMessage(chatContext.getAgent().getSystemPrompt()+"\n"+AgentPromptTemplates.getIgnoreSensitiveInfoPrompt()));
9
List<MessageEntity> messageHistory = chatContext.getMessageHistory();
10
for (MessageEntity messageEntity : messageHistory) {
11
if(messageEntity.isUserMessage()){
12
memory.add(new UserMessage(messageEntity.getContent()));
13
}else if(messageEntity.isAIMessage()){
14
memory.add(new AiMessage(messageEntity.getContent()));
15
}else if(messageEntity.isSystemMessage()){
16
memory.add(new SystemMessage(messageEntity.getContent()));
17
}
18
}
19
}

1
protected <T> void processChat(
2
Agent agent, T connection, MessageTransport<T> transport,
3
ChatContext chatContext, MessageEntity userEntity, MessageEntity llmEntity){
4
AtomicReference<StringBuilder> messageBuilder = new AtomicReference<>(new StringBuilder());
5
TokenStream tokenStream = agent.chat(chatContext.getUserMessage());
6
tokenStream.ignoreErrors();
7
// 部分响应处理
8
tokenStream.onPartialResponse(reply -> {
9
messageBuilder.get().append(reply);
10
transport.sendMessage(connection,
11
AgentChatResponse.build(reply, MessageType.TEXT));
12
});
13
14
// 完整响应处理
15
tokenStream.onCompleteResponse(chatResponse -> {
16
// 更新token信息
17
llmEntity.setTokenCount(chatResponse.tokenUsage().outputTokenCount());
18
llmEntity.setContent(chatResponse.aiMessage().text());
19
20
userEntity.setTokenCount(chatResponse.tokenUsage().inputTokenCount());
21
messageDomainService.updateMessage(userEntity);
22
23
// 保存AI消息
24
messageDomainService.saveMessageAndUpdateContext(
25
Collections.singletonList(llmEntity),
26
chatContext.getContextEntity());
27
28
// 发送结束消息
29
transport.sendEndMessage(connection,
30
AgentChatResponse.buildEndMessage(MessageType.TEXT));
31
});
32
33
// 错误处理
34
//        tokenStream.onError(throwable -> handleError(
35
//                connection, transport, chatContext,
36
//                messageBuilder.toString(), llmEntity, throwable));
37
38
// 工具执行处理
39
tokenStream.onToolExecuted(toolExecution -> {
40
if (!messageBuilder.get().isEmpty()){
41
transport.sendMessage(connection,
42
AgentChatResponse.buildEndMessage(MessageType.TEXT));
43
llmEntity.setContent(messageBuilder.toString());
44
messageDomainService.saveMessageAndUpdateContext(
45
Collections.singletonList(llmEntity),
46
chatContext.getContextEntity());
47
messageBuilder.set(new StringBuilder());
48
}
49
String message = "执行工具：" + toolExecution.request().name();
50
MessageEntity toolMessage = createLlmMessage(chatContext);
51
toolMessage.setMessageType(MessageType.TOOL_CALL);
52
toolMessage.setContent(message);
53
messageDomainService.saveMessageAndUpdateContext(
54
Collections.singletonList(toolMessage),
55
chatContext.getContextEntity());
56
57
transport.sendMessage(connection,
58
AgentChatResponse.buildEndMessage(message, MessageType.TOOL_CALL));
59
});
60
61
// 启动流处理
62
tokenStream.start();
63
}

§Agent交互设计对比分析：显式过程 vs 黑盒过程
§引言
在面向终端用户且支持多种工具（通过 MCP Server）的智能 Agent 应用中，交互方式的设计直接影响用户体验。本文比较两种截然不同的 Agent 交互设计方式：其一是 显式中间过程的交互式 Agent（展示任务拆解和工具调用过程），其二是 黑盒式 MCP Agent（隐藏过程，仅给出最终结果）。我们将从用户信任与可解释性、技术/普通用户体验差异、任务可控性与错误诊断、响应时间与流畅性、多工具协同透明度等维度进行深入分析，并探讨兼顾两者优点的混合式方案。
§两种 Agent 交互方式概述
§方案一：显式中间过程的交互式 Agent
这种方式在与用户交互时公开 Agent 解决问题的中间过程。系统会将复杂任务拆分成子任务，逐步执行，并在界面上实时显示每个子任务的进度、调用了哪些外部工具（MCP Server 提供的工具）以及执行状态等信息。任务的逻辑流程和工具调用由预先设定的系统代码或工作流来控制，实现明确的步骤序列。用户能够直观看到 Agent 的推理过程和进展，如同观察一个过程日志。
§方案二：黑盒式 MCP Agent
这种方式下，Agent 的任务规划和工具使用过程对用户是完全不可见的。用户仅提供输入请求，大语言模型（LLM）会自主决定如何调用 MCP Server 上的各种工具并直接给出最终答案。整个决策和操作过程被封装在模型内部，不向用户展示任务拆分、工具调用或中间结果。换言之，用户只看到 Agent 的最终输出，而 Agent 如何得到这个结果（使用了哪些步骤和工具）是一个黑盒。模型拥有高度自由来规划任务执行顺序和调用工具的方式，过程细节对用户透明度为零。
§关键维度对比
以下表格总结了显式交互 Agent 和黑盒 Agent 在几个关键用户体验维度上的差异：
比较维度
显式中间过程的交互式 Agent
黑盒式 MCP Agent
用户信任感与可解释性
透明展示推理步骤，提高结果可解释性，增强用户信任 (LLM Agents: The New Tech Marvel Everyone's Talking About)；用户可看到依据，结果更令人信服。但若过程繁杂或中间有错误，可能影响信任。
结果缺乏解释，用户需盲信 Agent 给出的答案；由于过程不可见，难以判断答案可靠性 (〖专家观点〗梁正教授：从可解释AI到可理解AI——基于算法治理的视角-清华大学人工智能国际治理研究院中文)。对于熟悉领域的用户，黑盒输出可能让人存疑。
面向技术用户 vs 普通用户
技术背景用户喜欢细节，能理解日志和工具步骤，觉得过程透明更可信；普通用户可能对细节不感兴趣，但简要的过程提示有助于理解来源。过多技术细节可能让非专业用户困惑。
普通用户更容易接受简洁直观的单轮对话，只看最终答案，不会被中间步骤干扰。技术用户则可能觉得信息不足，无法深入了解 Agent 决策，进而降低满意度。
任务可控性与出错诊断
系统明确分步执行，可在每步设置检查点和约束，提高可控性。如果某步失败，容易定位问题来源，便于调试和纠正 ([What is Explainable AI (XAI)?
IBM](https://www.ibm.com/think/topics/explainable-ai#:~:text=There%20are%20many%20advantages%20to,%C2%B9))。用户/开发者可发现哪一步出错，支持局部重试或调整。)。用户/开发者可发现哪一步出错，支持局部重试或调整。)
响应时间与交互流畅性
按步骤执行可能增加总耗时，尤其是串行调用多个工具时。但实时进度反馈让用户感觉等待更有把握 (Progress Indicators Make a Slow System Less Insufferable)。对于耗时长任务，用户看到进展条或步骤列表，耐心度提高。交互上多次小输出可能打断对话连贯性，但增强参与感。
模型直接输出结果，避免展示过程的开销，表面上响应更快。对简单任务，用户可以迅速得到答案，体验顺畅。对于耗时较长的任务，由于过程中无反馈，用户在等待时可能焦虑，不确定是否在处理。此外，对话流程更简洁（问答式），没有中途插入的系统信息。
多工具协同透明度
清晰显示用了哪些工具及其产出，让用户了解信息来源，提高多工具协作的透明度。例如，Agent 会注明“已调用数据库查询销售数据”“已使用地图 API 计算路线”，用户可以理解答案依据来自何处 ([AI...What to trust? A guide to AI-generated data use and reliability
MN Compass](https://www.mncompass.org/data-insights/articles/aiwhat-trust-guide-ai-generated-data-use-and-reliability#:~:text=1,Algorithms))。这有助于用户验证结果可信度，也让不同工具的贡献一目了然。)。这有助于用户验证结果可信度，也让不同工具的贡献一目了然。)
（注：上文引用中【11】强调了透明度对建立用户信任的重要性，【16】指出普通用户更关注易理解的解释与可信度，【13】说明了解决方案的推理过程有助于确保系统按预期工作并便于问题追查，【19】强调了进度反馈对用户等待体验的改善，【21】则提出可信的 AI 应清楚标明信息来源。）
§用户信任感与可解释性
显式过程 Agent 在用户信任度和可解释性方面通常表现更佳。 由于用户可以看到 Agent 解决问题的思路和步骤，他们更容易理解答案从何而来，从而增强对结果的信任 (LLM Agents: The New Tech Marvel Everyone's Talking About)。例如，一个提供显式过程的 Agent 在回答复杂问题时，会展示检索信息 → 分析推理 → 得出结论的过程。用户看到可靠的信息来源和逻辑链条，自然更愿意相信最终答案。此外，可解释的过程对高风险决策尤为重要：当 AI 给出的结果影响重大决策时，决策者往往需要了解依据才能放心采纳。
相比之下，黑盒 Agent 要求用户对结果“盲信”。由于缺乏解释，用户只能相信 AI 神秘地得出了正确答案。这在低风险、日常问题上或许问题不大，但在涉及专业领域或关乎重要利益时，很多用户会对一个黑盒答案持怀疑态度。如果 AI 给出的结果出错，用户事后回溯时也无从了解原因。值得注意的是，对于完全不懂内部机理的普通用户而言，黑盒 Agent 输出一个看似权威的答案，有时他们会选择相信（尤其当 AI 通常表现可靠时）；但对于稍具技术背景或对 AI 决策过程有所认识的用户，缺乏解释可能减弱信任，因为他们清楚 AI 可能出错且无法验证。
需要权衡的是，显式展示过程也有可能暴露 AI 的不确定性：如果用户在过程中看到 AI 反复试错或产生矛盾信息，反而可能降低对 AI 能力的信心。因此，理想情况下，显式 Agent 应展示清晰、有条理的推理链，并在发生错误时坦诚解释。有研究和业界观点指出，让 AI 具备透明度并提供解释是建立用户信任的关键 (LLM Agents: The New Tech Marvel Everyone's Talking About) (〖专家观点〗梁正教授：从可解释AI到可理解AI——基于算法治理的视角-清华大学人工智能国际治理研究院中文)。总的来说，在大多数情形下，透明度会带来更高的信任度和满意度，但需要确保解释对用户来说易于理解且有意义。
§面向技术用户 vs 普通用户的体验差异
不同背景的用户对 Agent 交互方式的偏好可能截然不同。对技术用户而言，显式过程往往更受欢迎。 这类用户（如开发者、数据分析师等）具备一定专业知识，乐于了解 AI 完成任务的详细步骤。他们会因为看到工具调用和中间结果而感到安心，认为系统更加可信可控。例如，一个开发者用户询问 Agent 执行数据分析，如果 Agent 展示“调用数据库查询 -> 得到结果 -> 绘制图表 -> 输出结论”的过程，他可以确认每步都合乎预期，否则能及时发现问题。这种透明性满足了技术用户对可解释性和掌控感的需求。
普通用户（非专业背景）则可能更偏好简洁、直接的交互。他们通常只关心最终结果是否解决了自己的问题，对于过程中用了什么 API、调用了几次工具并不感兴趣，甚至可能看不懂过多的技术细节 (〖专家观点〗梁正教授：从可解释AI到可理解AI——基于算法治理的视角-清华大学人工智能国际治理研究院中文)。对这类用户来说，显式展示每一步骤可能显得冗长，甚至令人困惑。过多的信息反而会增加认知负担，削弱用户体验。因此，黑盒 Agent 那种“一问一答、直达结果”的方式对普通用户更友好——他们提问，然后获得一个凝练的答复，不需要额外思考 AI 做了什么。特别在一些消费级应用（如智能助手查询天气、闲聊、小知识问答），用户期望的是快速、直接的答案，而非一个过程报告。
然而，即使是普通用户，在一些场景下也能受益于适度的过程提示。比如用户让 Agent 预订机票，如果黑盒 Agent 直接回复“已为您订好 XX 航班”，用户可能还是想知道它具体做了哪些操作（联系了哪个订票服务？使用了用户提供的哪些信息？）。显式 Agent 如果用非技术语言简单说明：“我查询了航班信息并预定了您首选时间的航班”，这会让普通用户更安心，而不会觉得“AI 瞒着我做了什么”。因此，关键在于解释的深度要匹配用户的认知水平：技术用户可以提供详尽日志，普通用户则提供概要性的说明和结果来源。总之，显式交互方式需要注意对不同用户分层呈现信息：既满足懂行者的好奇心，又不致淹没一般用户。
§任务可控性与出错诊断能力
在复杂任务和长流程中，Agent 的行为可控性以及错误出现时诊断纠偏的能力非常重要。显式中间过程方案通过固定的流程控制和可见的步骤，大大提升了任务的可控性。开发者可以对每个子任务设置规则和权限，例如限制某步只能调用特定安全工具，或在关键步骤要求二次确认，从而避免 Agent 自由规划可能带来的偏差或风险。同时，每一步都有明确输出，方便定位问题：如果最终结果不对，比起整个过程一头雾水，开发者或运维人员可以根据日志快速发现是哪一个子任务出了岔子。例如，某任务包括“查数据库 -> 算指标 -> 生成报告”三步，如果最终报告有误，日志可能显示“算指标”步骤出错（比如除零错误或调用了错误的 API），工程师即可针对性修复 (What is Explainable AI (XAI)? | IBM)。对于用户而言，显式过程也允许一定程度的干预：他们可以在过程中取消任务、调整参数，或者在看到中间结果不对劲时提早终止，比起等黑盒输出错误结果再反馈更高效。
黑盒式 Agent 则因为整个过程对外隐藏，可控性显著降低。模型可能自行采取一些未预料的步骤，调用额外的工具或者偏离最佳方案，而这些在过程外部无法监控。开发者只能通过调整提示或模型约束来间接影响其行为，但无法严格保证每一步都按预期进行。一旦结果出现错误或异常，诊断难度很大：由于看不到过程，工程师往往需要重跑任务并增加调试输出（如果可能）或审查模型调用日志，才能猜测问题发生在哪一步。这种事后分析既费时又不一定准确。而普通用户在面对黑盒 Agent 的错误时更是无能为力——他们只能得到一个错误信息或者不理想的答案，却不知道问题出在哪，无法采取补救措施。
另外，显式方案能更好地处理失败：如果某工具调用失败，系统可以通知用户或采取备用方案。例如，当 Agent 调用 API 超时，显式 UI 可以提示“X 服务暂时无响应，正在重试”或让用户决定是否继续；黑盒模式下，模型可能收到错误后要么放弃要么编造一个次优答案，用户看到的只是最终的失败结果（甚至可能不明确失败原因）。总之，在需要高度可靠和可维护的系统中，显式中间过程提供了对 Agent 行为的监督机制，既利于及时纠错，也方便持续优化。而黑盒模式虽然简洁，但缺乏过程监督，使得问题难以追踪和修复(What is Explainable AI (XAI)? | IBM)。
§响应时间与交互流畅性
响应速度和交互的流畅程度是影响用户满意度的关键因素之一。显式过程 Agent 由于将任务拆解执行，可能在总耗时上略有增加——每个子任务串行执行并显示，其实质相当于多个请求-响应的累计。然而，这种方式通过逐步反馈来改善主观体验。用户在提出请求后，不必一直面对空白等待，而是很快就能看到 Agent 开始行动（哪怕只是简单的“正在分析…”提示）。研究表明，明确的进度指示会使用户更安心，感觉等待时间变短 (Progress Indicators Make a Slow System Less Insufferable)。例如，当用户请求生成一份详细报告，显式 Agent 可以分段反馈：“正在汇总数据…(25%)”、“正在生成图表…(50%)”、“撰写报告…(75%)”，最终“完成！”。这些阶段性的更新让用户知道任务在顺利推进，交互过程更具可感知性。特别对于耗时较长的任务，显式方案的流畅度反而更好，因为用户不会怀疑系统是否卡住或无响应。
黑盒 Agent 在单轮对话中往往追求一跃到位的答案输出。在简单或快速任务下，它的表观响应时间可能更短——用户提出问题，稍等片刻直接拿到完整答案，中间没有多余信息插入，互动显得干净利落。这种方式非常适合那些即时性的问答、闲聊或简单工具调用（如查天气、算一道简单数学题），几乎感觉不到过程存在，因而体验顺畅直接。然而，当处理复杂任务需要调用多个工具或长时间计算时，黑盒 Agent 的劣势显现：用户可能长时间看不到任何输出，也不知道系统是否在工作。这不仅容易令人焦虑，还可能因为等待过久而中途放弃。为了缓解这种情况，实际应用中经常会用“加载中”动画或占位回复来告知用户正在处理，但相较于显式展示真实进展，这种抽象的等待反馈作用有限。
在对话连贯性方面，黑盒方式确实保持了聊天记录的简洁——一个提问对应一个回答，没有过程插话。而显式方式如果不加区分地把步骤当作消息发送，可能使对话记录混杂了大量系统信息，影响用户翻阅历史时的体验。理想的实现可以将过程反馈与主要回答区分显示（例如在 UI 上用不同区域或折叠方式呈现），既保证主要对话的简洁，又提供进度透明度。总体而言，显式 Agent 略牺牲了某些即时性，但通过丰富的反馈提升了交互的流畅感和用户对时间的感知控制；黑盒 Agent 侧重结果导向，在任务简短时体验极佳，但在任务复杂或耗时时可能显得“沉默”而降低流畅度。
§多工具协同使用时的透明度
当 Agent 需要联合多个工具协同完成任务时，信息透明与否对用户理解结果十分重要。显式交互式 Agent在这方面的优势是让用户清楚知道哪些工具被用了、各自贡献了什么。例如，一个智能助理需要先调用日历 API 查询会议时间，再调用地图服务计算路线，最后发邮件通知与会者。显式 Agent 会将这些步骤展示或告知用户：“查到您的日程表显示会议在明天 10 点（来自日历）；已用地图服务计算从您位置到会场需要 30 分钟车程；已发送邮件通知参会者。” 用户由此明白最终建议（比如提醒几点出发）是基于可靠的数据。这样的透明度增强了多工具场景下的结果可信度，因为用户可以追踪每个数据点的来源 (AI...What to trust? A guide to AI-generated data use and reliability | MN Compass)。在专业应用中（如商业智能分析），显示使用的数据源和分析工具也满足了审计需求——相关人员可以验证每个环节，没有黑箱操作。
黑盒 Agent 在多工具协作场景下则让用户处于信息盲区。用户只得到最后的结论，却不知道 Agent 背后可能调用了哪些系统。例如，Agent 回答“你公司的本月销售额是 100 万元”，用户无法确定它是查了企业内部数据库得出的，还是基于某种预测模型估算的。如果有多个工具协同，这种不透明可能引发疑虑：结果是否整合了所有必要信息？有没有遗漏某个数据源？在严谨场景中，用户甚至需要手动去核实这些可能用到的数据，反而降低效率和信任度。业内对于AI 输出可信性的建议之一，就是要求 AI 明确引用其信息来源 (AI...What to trust? A guide to AI-generated data use and reliability | MN Compass)。黑盒 Agent 显然不符合这点，因为它默认不披露来源。
此外，透明度不足还会影响用户对 Agent 能力边界的认知。如果 Agent 一直隐藏工具调用，用户可能高估 AI 自身的能力（以为它什么都知道），当某次 Agent 因为没有使用应有的工具而答错时，用户会困惑“它怎么连这都不知道？”。相反，显式方式让用户了解 AI 是通过工具来扩展能力，例如需要搜索时就去搜，需要计算时就用计算器，从而对 AI 的定位有清晰认知，不至于期待不切实际的全能。然而，在一般消费场景，也要避免过多打扰用户：并非每次调用都需要详尽说明，否则用户可能觉得信息噪杂。关键是在涉及结果依据的时候提供透明度，例如引用外部知识、数据来源、工具名称等，以建立可信度；对用户不关心的底层调用则可以省略。总之，多工具协同下，适度的透明度能帮助用户理解 AI 的工作流和信息来源，提升可靠性和理解度，而黑盒模式下这部分优势缺失。
§混合式交互方案的探索
综合以上分析，我们考虑是否存在兼顾两种模式优点的混合式交互方式。理想的方案既要保持 MCP Agent 利用大模型自主规划、多工具灵活调用的智能性和高效性，又要在关键之处提供适度的过程可见性来增强用户信任和可控性。
一种可行思路是引入“灰盒”交互模式：即大部分简单交互依然采用黑盒直答，以保持简洁流畅，但在涉及复杂任务或用户高关注度的信息时，提供适当的解释和过程透明。例如：
◦ 摘要推理路径：Agent 在给出最终答案的同时，附上一段简短说明，概括其解决问题的思路和关键步骤。这个说明用自然语言描述，让普通用户也能看懂。例如回答之后附注：“（我先查询了最新汇率，然后进行了金额换算。）”
◦ 列出使用的工具：对于涉及外部知识或操作的回答，在结果下方标明“信息来源：数据库 X，API Y”等，或者用图标提示调用过的工具。这样用户无需看详细日志也能了解 Agent 获取信息的途径，满足 (AI...What to trust? A guide to AI-generated data use and reliability | MN Compass)所倡导的来源透明。
◦ 关键中间结论：如果任务链很长，Agent 可以在完成后提供关键中间结果的记录。例如：“查询到的销售数据：100万元；市场趋势分析结果：增长5%；综合这两点给出的建议如下…”。这种方式让用户明白重要的中间产出，而不必看所有细节。
◦ 交互式细节查询：默认不展示详细过程，但允许用户在需要时追问。例如用户可以问：“你是怎么得到这个结果的？” 此时 Agent 切换到显式模式，提供分步解释或详尽日志。这对技术用户尤为有用，让他们在默认简洁模式和深入细节模式之间自由切换。
◦ 可控的过程展示：UI 层面，可以将 Agent 的推理过程绘制为流程图或进度条供感兴趣者查看，而一般用户可以无视。或者设计为折叠面板，用户点击“显示步骤”才展开细节。这相当于给用户选择权，避免信息过载的同时又确保透明度可得。
通过上述方法，Agent 在大多数情况下仍能自主高速运转（不需要人工逐步核对每一步），但用户对其决策路径不再一无所知。这种折中方案既维护了黑盒 Agent 的高效率和低打扰，又借鉴了显式 Agent 的可解释性优势。举例来说，一款面向企业的数据分析 AI 助手平时直接给经理报表结果，但在报告里附有“数据来源和分析方法”章节，让经理在需要时验证细节；而对于一般性聊天查询则不增加额外说明，以免冗长。
需要注意的是，混合模式下信息呈现的方式和时机很关键。我们应避免回到显式模式的老路——过多的信息可能再次淹没用户。因此强调“适度”二字：只在必要且有益的场合提供透明度。例如，当 AI 的结论可能引发用户质疑时（数据出人意料、涉及专业领域等），给出依据会提高可信度；反之对于显而易见或无关痛痒的结果，可省略过程描述。此外，还可以借助UI 设计来平衡，比如用分层显示、提示语等方式将解释融入输出但不喧宾夺主。
§结语
显式中间过程的交互式 Agent 和黑盒式 MCP Agent 各有优劣：前者透明可查、便于信任和调试，但可能冗长复杂；后者简洁高效、用户负担低，但缺乏可解释性和控制。根据应用场景和用户群体，设计者应权衡取舍。对于安全要求高或专业性强的场景，倾向于显式或灰盒方案以确保透明可控；对于日常简易任务，则黑盒方案足以提供良好体验。展望未来，混合式的交互范式或将成为主流——通过智能地调节信息透明度，让 AI 助手既“聪明”又“可信”。这样，我们才能在享受 MCP Agent 强大功能的同时，最大限度地提升终端用户的使用满意度和信心。
