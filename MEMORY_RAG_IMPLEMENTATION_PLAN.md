# Memory + RAG é›†æˆå®æ–½è®¡åˆ’

## ğŸ“‹ æ€»ä½“ç›®æ ‡

å®ç°ä¸€ä¸ªç”Ÿäº§çº§çš„ **Memory + RAG** ç³»ç»Ÿï¼Œå…·å¤‡ï¼š
- âœ… ç»Ÿä¸€çš„ Memory æ¥å£æŠ½è±¡
- âœ… æ•°æ®åº“ + ç¼“å­˜åŒå†™æœºåˆ¶ï¼ˆåŸå­æ€§ï¼‰
- âœ… TTL ç¼“å­˜è‡ªåŠ¨å›æº¯
- âœ… å·¥ä½œè®°å¿†å‹ç¼© + é•¿æœŸè®°å¿†å‘é‡åŒ–
- âœ… RAG ä¸ªäººçŸ¥è¯†åº“éš”ç¦»
- âœ… æ€§èƒ½ç›‘æ§ï¼ˆå‘½ä¸­ç‡ã€å›æº¯è€—æ—¶ï¼‰

---

## ğŸ¯ æ¶æ„è®¾è®¡

### æ¶æ„åˆ†å±‚ï¼ˆä¸¥æ ¼éµå¾ª DDDï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Interface Layer                          â”‚
â”‚  - ç›‘æ§ API (metrics, cache_stats)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Application Layer                           â”‚
â”‚  - CompositeMemoryService (ç»„åˆæ¨¡å¼ç¼–æ’)                  â”‚
â”‚  - MemoryMetricsCollector (ç›‘æ§æŒ‡æ ‡)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Domain Layer                             â”‚
â”‚  Ports (Pure Python Protocols):                         â”‚
â”‚  - MemoryProvider (æŠ½è±¡æ¥å£)                             â”‚
â”‚  - MemoryCache (ç¼“å­˜æ¥å£)                                â”‚
â”‚  - MemoryCompressor (å‹ç¼©ç­–ç•¥)                           â”‚
â”‚                                                          â”‚
â”‚  Entities:                                               â”‚
â”‚  - WorkingMemory (å·¥ä½œè®°å¿†å€¼å¯¹è±¡)                         â”‚
â”‚  - MemoryMetrics (ç›‘æ§æŒ‡æ ‡å€¼å¯¹è±¡)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Infrastructure Layer                           â”‚
â”‚  Adapters (Implementations):                            â”‚
â”‚  - DatabaseMemoryStore (å®ç° MemoryProvider)             â”‚
â”‚  - InMemoryCache (å®ç° MemoryCache + TTL)                â”‚
â”‚  - TFIDFCompressor (å®ç° MemoryCompressor)               â”‚
â”‚  - EmbeddingIndexBuilder (å‘é‡ç´¢å¼•æ„å»º)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ æ•°æ®æµè®¾è®¡

### 1ï¸âƒ£ å†™å…¥æµç¨‹ï¼ˆåŸå­åŒå†™ï¼‰

```
User Message
    â”‚
    â–¼
CompositeMemoryService.append(message)
    â”‚
    â”œâ”€1ï¸âƒ£â”€â–º DatabaseMemoryStore.save(message)  [DB äº‹åŠ¡]
    â”‚        â”œâ”€ Success â†’ commit
    â”‚        â””â”€ Failure â†’ rollback + raise exception
    â”‚
    â””â”€2ï¸âƒ£â”€â–º InMemoryCache.put(workflow_id, message)
             â”œâ”€ Success â†’ update last_access_time
             â””â”€ Failure â†’ log warning + mark cache as invalid
```

**åŸå­æ€§ä¿è¯ï¼š**
- DB å†™å…¥å¤±è´¥ â†’ æŠ›å‡ºå¼‚å¸¸ï¼Œæ•´ä¸ªæ“ä½œå›æ»š
- Cache å†™å…¥å¤±è´¥ â†’ è®°å½•æ—¥å¿—ï¼Œæ ‡è®°ç¼“å­˜å¤±æ•ˆï¼ˆä¸‹æ¬¡è¯»å–è§¦å‘å›æº¯ï¼‰

---

### 2ï¸âƒ£ è¯»å–æµç¨‹ï¼ˆç¼“å­˜ä¼˜å…ˆ + è‡ªåŠ¨å›æº¯ï¼‰

```
CompositeMemoryService.load_recent(workflow_id, last_n)
    â”‚
    â–¼
InMemoryCache.get(workflow_id)
    â”‚
    â”œâ”€ Cache Hit + TTL Valid
    â”‚   â””â”€â–º Return cached messages (å¿«é€Ÿè·¯å¾„)
    â”‚
    â””â”€ Cache Miss / TTL Expired / Invalid
        â”‚
        â–¼
      DatabaseMemoryStore.find_by_workflow_id(workflow_id, limit=100)
        â”‚
        â–¼
      MemoryCompressor.compress(messages, max_tokens=4000)
        â”œâ”€ 1ï¸âƒ£ TF-IDF è®¡ç®—é‡è¦æ€§å¾—åˆ†
        â”œâ”€ 2ï¸âƒ£ ä¿ç•™æœ€è¿‘ min_messages æ¡
        â”œâ”€ 3ï¸âƒ£ ç§»é™¤ä½åˆ†æ¶ˆæ¯ç›´åˆ°æ»¡è¶³ token é™åˆ¶
        â””â”€ 4ï¸âƒ£ è¿”å›å‹ç¼©åçš„æ¶ˆæ¯åˆ—è¡¨
        â”‚
        â–¼
      InMemoryCache.put(workflow_id, compressed_messages)
        â”‚
        â–¼
      Return compressed_messages
```

**ç¼“å­˜ç­–ç•¥ï¼š**
- TTL: 15 åˆ†é’Ÿï¼ˆå¯é…ç½®ï¼‰
- æœ€å¤§å®¹é‡ï¼š1000 ä¸ª workflowï¼ˆLRU æ·˜æ±°ï¼‰
- æ¯ä¸ª workflow æœ€å¤šç¼“å­˜ 50 æ¡æ¶ˆæ¯

---

### 3ï¸âƒ£ æœç´¢æµç¨‹ï¼ˆå‘é‡ + å…³é”®è¯æ··åˆï¼‰

```
CompositeMemoryService.search(query, workflow_id)
    â”‚
    â”œâ”€1ï¸âƒ£â”€â–º InMemoryCache.search_index(query)
    â”‚        â””â”€ å€’æ’ç´¢å¼• + TF-IDF å¿«é€ŸåŒ¹é…
    â”‚             â””â”€â–º Top 20 candidates
    â”‚
    â””â”€2ï¸âƒ£â”€â–º EmbeddingIndexBuilder.vector_search(query_embedding)
             â”œâ”€ ChromaDB å‘é‡ç›¸ä¼¼åº¦æœç´¢
             â””â”€â–º Top 10 results
    â”‚
    â–¼
Merge + Rerank (RRF ç®—æ³•)
    â””â”€â–º Final Top 5 results
```

---

## ğŸ“ åˆ†é˜¶æ®µå®æ–½è®¡åˆ’ï¼ˆTDD é©±åŠ¨ï¼‰

### Phase 1: Domain å±‚ - çº¯æ¥å£å®šä¹‰ï¼ˆ2 æ–‡ä»¶ï¼‰

**ç›®æ ‡ï¼š** å®šä¹‰æ ¸å¿ƒæŠ½è±¡ï¼Œæ— ä»»ä½•æ¡†æ¶ä¾èµ–

#### 1.1 å®šä¹‰ MemoryProvider Protocol

**æ–‡ä»¶ï¼š** `src/domain/ports/memory_provider.py`

```python
from typing import Protocol
from src.domain.entities.chat_message import ChatMessage

class MemoryProvider(Protocol):
    """Memory ç»Ÿä¸€æ¥å£æŠ½è±¡"""

    def append(self, message: ChatMessage) -> None:
        """è¿½åŠ æ¶ˆæ¯åˆ°è®°å¿†ä¸­"""
        ...

    def load_recent(self, workflow_id: str, last_n: int = 10) -> list[ChatMessage]:
        """åŠ è½½æœ€è¿‘ N æ¡æ¶ˆæ¯"""
        ...

    def search(self, query: str, workflow_id: str, threshold: float = 0.5) -> list[tuple[ChatMessage, float]]:
        """æœç´¢ç›¸å…³æ¶ˆæ¯"""
        ...

    def clear(self, workflow_id: str) -> None:
        """æ¸…ç©ºæŒ‡å®š workflow çš„è®°å¿†"""
        ...
```

#### 1.2 å®šä¹‰ MemoryCache Protocol

**æ–‡ä»¶ï¼š** `src/domain/ports/memory_cache.py`

```python
from typing import Protocol
from src.domain.entities.chat_message import ChatMessage

class MemoryCache(Protocol):
    """ç¼“å­˜æ¥å£æŠ½è±¡"""

    def get(self, workflow_id: str) -> list[ChatMessage] | None:
        """è·å–ç¼“å­˜ï¼ˆNone è¡¨ç¤ºæœªå‘½ä¸­æˆ–è¿‡æœŸï¼‰"""
        ...

    def put(self, workflow_id: str, messages: list[ChatMessage]) -> None:
        """æ›´æ–°ç¼“å­˜"""
        ...

    def invalidate(self, workflow_id: str) -> None:
        """ä¸»åŠ¨å¤±æ•ˆ"""
        ...

    def is_valid(self, workflow_id: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        ...
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/unit/domain/ports/test_memory_provider.py`
   - æµ‹è¯• Protocol æ˜¯å¦å¯è¢«æ­£ç¡®ç»§æ‰¿
   - æµ‹è¯•æ–¹æ³•ç­¾åæ˜¯å¦ç¬¦åˆé¢„æœŸ
2. å®ç°æ¥å£ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

### Phase 2: Infrastructure å±‚ - é€‚é…å™¨å®ç°ï¼ˆ3 æ–‡ä»¶ï¼‰

#### 2.1 DatabaseMemoryStoreï¼ˆç°æœ‰ Repository çš„åŒ…è£…ï¼‰

**æ–‡ä»¶ï¼š** `src/infrastructure/memory/database_memory_store.py`

```python
from src.domain.ports.memory_provider import MemoryProvider
from src.domain.ports.chat_message_repository import ChatMessageRepository
from src.domain.entities.chat_message import ChatMessage

class DatabaseMemoryStore:
    """æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨ï¼ˆå®ç° MemoryProviderï¼‰"""

    def __init__(self, repository: ChatMessageRepository):
        self._repository = repository

    def append(self, message: ChatMessage) -> None:
        """å†™å…¥æ•°æ®åº“ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰"""
        try:
            self._repository.save(message)
        except Exception as e:
            # è®°å½•æ—¥å¿— + é‡æ–°æŠ›å‡º
            raise DatabaseWriteError(f"Failed to save message: {e}") from e

    def load_recent(self, workflow_id: str, last_n: int = 10) -> list[ChatMessage]:
        messages = self._repository.find_by_workflow_id(workflow_id, limit=last_n * 2)
        return messages[-last_n:]  # åªå–æœ€è¿‘ N æ¡

    def search(self, query: str, workflow_id: str, threshold: float = 0.5) -> list[tuple[ChatMessage, float]]:
        return self._repository.search(workflow_id, query, threshold)

    def clear(self, workflow_id: str) -> None:
        self._repository.delete_by_workflow_id(workflow_id)
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/unit/infrastructure/memory/test_database_memory_store.py`
   - æµ‹è¯•æ­£å¸¸å†™å…¥
   - æµ‹è¯•å¼‚å¸¸å¤„ç†
   - æµ‹è¯•è¯»å–é€»è¾‘
2. å®ç°ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

#### 2.2 InMemoryCacheï¼ˆTTL + LRUï¼‰

**æ–‡ä»¶ï¼š** `src/infrastructure/memory/in_memory_cache.py`

```python
from collections import OrderedDict
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict
from src.domain.entities.chat_message import ChatMessage

@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    messages: list[ChatMessage]
    last_access: datetime
    is_valid: bool = True

class InMemoryCache:
    """åŸºäºå†…å­˜çš„ TTL ç¼“å­˜ï¼ˆLRU æ·˜æ±°ç­–ç•¥ï¼‰"""

    def __init__(
        self,
        ttl_seconds: int = 900,  # 15 åˆ†é’Ÿ
        max_workflows: int = 1000,
        max_messages_per_workflow: int = 50
    ):
        self._ttl = timedelta(seconds=ttl_seconds)
        self._max_workflows = max_workflows
        self._max_messages = max_messages_per_workflow
        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()

        # ç›‘æ§æŒ‡æ ‡
        self._hits = 0
        self._misses = 0

    def get(self, workflow_id: str) -> list[ChatMessage] | None:
        """è·å–ç¼“å­˜ï¼ˆæ£€æŸ¥ TTLï¼‰"""
        if workflow_id not in self._cache:
            self._misses += 1
            return None

        entry = self._cache[workflow_id]

        # æ£€æŸ¥ TTL
        if datetime.utcnow() - entry.last_access > self._ttl:
            self._misses += 1
            del self._cache[workflow_id]
            return None

        # æ£€æŸ¥æœ‰æ•ˆæ€§æ ‡è®°
        if not entry.is_valid:
            self._misses += 1
            return None

        # å‘½ä¸­ï¼šæ›´æ–°è®¿é—®æ—¶é—´ + LRU ç§»åŠ¨
        entry.last_access = datetime.utcnow()
        self._cache.move_to_end(workflow_id)
        self._hits += 1

        return entry.messages.copy()

    def put(self, workflow_id: str, messages: list[ChatMessage]) -> None:
        """æ›´æ–°ç¼“å­˜ï¼ˆLRU æ·˜æ±°ï¼‰"""
        # é™åˆ¶æ¶ˆæ¯æ•°é‡
        trimmed_messages = messages[-self._max_messages:]

        # æ›´æ–°æˆ–æ’å…¥
        self._cache[workflow_id] = CacheEntry(
            messages=trimmed_messages,
            last_access=datetime.utcnow()
        )
        self._cache.move_to_end(workflow_id)

        # LRU æ·˜æ±°
        while len(self._cache) > self._max_workflows:
            self._cache.popitem(last=False)  # ç§»é™¤æœ€æ—§çš„

    def invalidate(self, workflow_id: str) -> None:
        """æ ‡è®°å¤±æ•ˆï¼ˆä¸åˆ é™¤ï¼Œè§¦å‘ä¸‹æ¬¡å›æº¯ï¼‰"""
        if workflow_id in self._cache:
            self._cache[workflow_id].is_valid = False

    def is_valid(self, workflow_id: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§"""
        if workflow_id not in self._cache:
            return False
        entry = self._cache[workflow_id]
        return entry.is_valid and (datetime.utcnow() - entry.last_access <= self._ttl)

    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self._hits + self._misses
        hit_rate = self._hits / total if total > 0 else 0.0

        return {
            "hits": self._hits,
            "misses": self._misses,
            "hit_rate": hit_rate,
            "cached_workflows": len(self._cache),
            "ttl_seconds": self._ttl.total_seconds()
        }
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/unit/infrastructure/memory/test_in_memory_cache.py`
   - æµ‹è¯•åŸºæœ¬ get/put
   - æµ‹è¯• TTL è¿‡æœŸ
   - æµ‹è¯• LRU æ·˜æ±°
   - æµ‹è¯• invalidate
   - æµ‹è¯•ç»Ÿè®¡æŒ‡æ ‡
2. å®ç°ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

#### 2.3 TFIDFCompressorï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰

**æ–‡ä»¶ï¼š** `src/infrastructure/memory/tfidf_compressor.py`

```python
from collections import Counter
import math
from src.domain.entities.chat_message import ChatMessage

class TFIDFCompressor:
    """åŸºäº TF-IDF çš„æ¶ˆæ¯é‡è¦æ€§è¯„ä¼°å™¨"""

    def compress(
        self,
        messages: list[ChatMessage],
        max_tokens: int = 4000,
        min_messages: int = 2
    ) -> list[ChatMessage]:
        """å‹ç¼©æ¶ˆæ¯åˆ—è¡¨åˆ°æŒ‡å®š token é™åˆ¶"""

        if len(messages) <= min_messages:
            return messages

        # 1. è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ token æ•°
        message_tokens = [self._estimate_tokens(msg.content) for msg in messages]
        total_tokens = sum(message_tokens)

        if total_tokens <= max_tokens:
            return messages

        # 2. è®¡ç®— TF-IDF åˆ†æ•°
        scores = self._calculate_tfidf_scores(messages)

        # 3. æŒ‰æ—¶é—´å€’åºæ’åºï¼ˆä¿ç•™æœ€è¿‘çš„ï¼‰
        sorted_indices = list(range(len(messages)))
        sorted_indices.sort(key=lambda i: messages[i].timestamp, reverse=True)

        # 4. è´ªå¿ƒé€‰æ‹©ï¼šä¼˜å…ˆä¿ç•™æœ€è¿‘ + é«˜åˆ†æ¶ˆæ¯
        selected = []
        current_tokens = 0

        # å¼ºåˆ¶ä¿ç•™æœ€è¿‘ min_messages æ¡
        for i in range(min(min_messages, len(messages))):
            idx = sorted_indices[i]
            selected.append(idx)
            current_tokens += message_tokens[idx]

        # æŒ‰åˆ†æ•°é€‰æ‹©å‰©ä½™æ¶ˆæ¯
        remaining = [(idx, scores[idx]) for idx in sorted_indices[min_messages:]]
        remaining.sort(key=lambda x: x[1], reverse=True)

        for idx, score in remaining:
            if current_tokens + message_tokens[idx] <= max_tokens:
                selected.append(idx)
                current_tokens += message_tokens[idx]
            else:
                break

        # 5. æŒ‰æ—¶é—´é¡ºåºè¿”å›
        selected.sort()
        return [messages[i] for i in selected]

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®— token æ•°é‡ï¼ˆå¯å‘å¼ï¼‰"""
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        other_chars = len(text) - chinese_chars
        return int(chinese_chars / 1.3 + other_chars / 4)

    def _calculate_tfidf_scores(self, messages: list[ChatMessage]) -> list[float]:
        """è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ TF-IDF åˆ†æ•°"""
        # æ„å»ºè¯é¢‘è¡¨
        all_words = []
        message_words = []

        for msg in messages:
            words = self._tokenize(msg.content)
            message_words.append(words)
            all_words.extend(words)

        # è®¡ç®— IDF
        word_doc_count = Counter()
        for words in message_words:
            word_doc_count.update(set(words))

        num_docs = len(messages)
        idf = {word: math.log(num_docs / count) for word, count in word_doc_count.items()}

        # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„ TF-IDF å¾—åˆ†
        scores = []
        for words in message_words:
            word_count = Counter(words)
            total_words = len(words)

            if total_words == 0:
                scores.append(0.0)
                continue

            tfidf_sum = sum(
                (count / total_words) * idf.get(word, 0.0)
                for word, count in word_count.items()
            )
            scores.append(tfidf_sum)

        return scores

    def _tokenize(self, text: str) -> list[str]:
        """ç®€å•åˆ†è¯ï¼ˆç©ºæ ¼åˆ†éš” + ä¸­æ–‡å­—ç¬¦ï¼‰"""
        words = []
        for char in text:
            if '\u4e00' <= char <= '\u9fff':
                words.append(char)
        words.extend(text.split())
        return [w for w in words if w.strip()]
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/unit/infrastructure/memory/test_tfidf_compressor.py`
   - æµ‹è¯•æ— éœ€å‹ç¼©åœºæ™¯
   - æµ‹è¯• token é™åˆ¶ç”Ÿæ•ˆ
   - æµ‹è¯• min_messages ä¿è¯
   - æµ‹è¯• TF-IDF åˆ†æ•°è®¡ç®—
2. å®ç°ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

### Phase 3: Application å±‚ - ç»„åˆç¼–æ’ï¼ˆ1 æ–‡ä»¶ï¼‰

#### 3.1 CompositeMemoryServiceï¼ˆæ ¸å¿ƒç¼–æ’ï¼‰

**æ–‡ä»¶ï¼š** `src/application/services/composite_memory_service.py`

```python
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional
import logging

from src.domain.entities.chat_message import ChatMessage
from src.infrastructure.memory.database_memory_store import DatabaseMemoryStore
from src.infrastructure.memory.in_memory_cache import InMemoryCache
from src.infrastructure.memory.tfidf_compressor import TFIDFCompressor

logger = logging.getLogger(__name__)

@dataclass
class MemoryMetrics:
    """å†…å­˜æ“ä½œæŒ‡æ ‡"""
    cache_hit_rate: float
    fallback_count: int
    compression_ratio: float
    avg_fallback_time_ms: float
    last_updated: datetime = field(default_factory=datetime.utcnow)

class CompositeMemoryService:
    """ç»„åˆå¼å†…å­˜æœåŠ¡ï¼ˆåŒå†™ + å›æº¯ + å‹ç¼©ï¼‰"""

    def __init__(
        self,
        db_store: DatabaseMemoryStore,
        cache: InMemoryCache,
        compressor: TFIDFCompressor,
        max_context_tokens: int = 4000
    ):
        self._db = db_store
        self._cache = cache
        self._compressor = compressor
        self._max_tokens = max_context_tokens

        # ç›‘æ§æŒ‡æ ‡
        self._fallback_times = []
        self._compression_ratios = []

    def append(self, message: ChatMessage) -> None:
        """åŸå­åŒå†™ï¼šDB â†’ Cache"""

        # 1. å†™å…¥æ•°æ®åº“ï¼ˆå¤±è´¥åˆ™æŠ›å¼‚å¸¸ï¼‰
        try:
            self._db.append(message)
        except Exception as e:
            logger.error(f"Database write failed for message {message.id}: {e}")
            raise

        # 2. æ›´æ–°ç¼“å­˜ï¼ˆå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼‰
        try:
            # è¯»å–å½“å‰ç¼“å­˜
            cached = self._cache.get(message.workflow_id)
            if cached is None:
                cached = []

            # è¿½åŠ æ–°æ¶ˆæ¯
            cached.append(message)

            # æ›´æ–°ç¼“å­˜
            self._cache.put(message.workflow_id, cached)
        except Exception as e:
            logger.warning(f"Cache write failed for workflow {message.workflow_id}: {e}")
            # æ ‡è®°ç¼“å­˜å¤±æ•ˆï¼Œè§¦å‘ä¸‹æ¬¡å›æº¯
            self._cache.invalidate(message.workflow_id)

    def load_recent(
        self,
        workflow_id: str,
        last_n: int = 10
    ) -> list[ChatMessage]:
        """åŠ è½½æœ€è¿‘æ¶ˆæ¯ï¼ˆç¼“å­˜ä¼˜å…ˆ + è‡ªåŠ¨å›æº¯ï¼‰"""

        # 1. å°è¯•ä»ç¼“å­˜è¯»å–
        cached = self._cache.get(workflow_id)
        if cached is not None:
            logger.debug(f"Cache hit for workflow {workflow_id}")
            return cached[-last_n:]

        # 2. ç¼“å­˜æœªå‘½ä¸­ â†’ å›æº¯åˆ°æ•°æ®åº“
        logger.info(f"Cache miss for workflow {workflow_id}, falling back to database")

        start_time = datetime.utcnow()

        # 3. ä»æ•°æ®åº“åŠ è½½
        messages = self._db.load_recent(workflow_id, last_n=100)  # å¤šå–ä¸€äº›ç”¨äºå‹ç¼©

        if not messages:
            return []

        # 4. å‹ç¼©ï¼ˆå¦‚æœè¶…è¿‡ token é™åˆ¶ï¼‰
        original_count = len(messages)
        compressed = self._compressor.compress(
            messages,
            max_tokens=self._max_tokens,
            min_messages=min(2, last_n)
        )

        # 5. æ›´æ–°ç¼“å­˜
        self._cache.put(workflow_id, compressed)

        # 6. è®°å½•æŒ‡æ ‡
        fallback_time = (datetime.utcnow() - start_time).total_seconds() * 1000
        self._fallback_times.append(fallback_time)

        compression_ratio = len(compressed) / original_count if original_count > 0 else 1.0
        self._compression_ratios.append(compression_ratio)

        logger.info(
            f"Fallback completed in {fallback_time:.2f}ms, "
            f"compressed {original_count} â†’ {len(compressed)} messages"
        )

        return compressed[-last_n:]

    def search(
        self,
        query: str,
        workflow_id: str,
        threshold: float = 0.5
    ) -> list[tuple[ChatMessage, float]]:
        """æœç´¢ç›¸å…³æ¶ˆæ¯ï¼ˆç›´æ¥æŸ¥è¯¢æ•°æ®åº“ï¼‰"""
        # æœç´¢æ“ä½œç›´æ¥æŸ¥è¯¢ DBï¼Œå› ä¸ºéœ€è¦å…¨é‡æ•°æ®
        return self._db.search(query, workflow_id, threshold)

    def clear(self, workflow_id: str) -> None:
        """æ¸…ç©ºè®°å¿†ï¼ˆDB + Cacheï¼‰"""
        self._db.clear(workflow_id)
        self._cache.invalidate(workflow_id)

    def get_metrics(self) -> MemoryMetrics:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        cache_stats = self._cache.get_stats()

        avg_fallback_time = (
            sum(self._fallback_times) / len(self._fallback_times)
            if self._fallback_times else 0.0
        )

        avg_compression_ratio = (
            sum(self._compression_ratios) / len(self._compression_ratios)
            if self._compression_ratios else 1.0
        )

        return MemoryMetrics(
            cache_hit_rate=cache_stats["hit_rate"],
            fallback_count=len(self._fallback_times),
            compression_ratio=avg_compression_ratio,
            avg_fallback_time_ms=avg_fallback_time
        )
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/unit/application/services/test_composite_memory_service.py`
   - æµ‹è¯•åŒå†™æˆåŠŸ
   - æµ‹è¯• DB å†™å…¥å¤±è´¥æŠ›å¼‚å¸¸
   - æµ‹è¯• Cache å†™å…¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
   - æµ‹è¯•ç¼“å­˜å‘½ä¸­
   - æµ‹è¯•ç¼“å­˜æœªå‘½ä¸­å›æº¯
   - æµ‹è¯•å‹ç¼©é€»è¾‘
   - æµ‹è¯•æŒ‡æ ‡æ”¶é›†
2. å®ç°ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

### Phase 4: é›†æˆåˆ°å¯¹è¯æµï¼ˆ1 æ–‡ä»¶ä¿®æ”¹ï¼‰

#### 4.1 å¢å¼º WorkflowChatServiceEnhanced

**æ–‡ä»¶ï¼š** `src/domain/services/workflow_chat_service_enhanced.py`ï¼ˆä¿®æ”¹ï¼‰

**ä¿®æ”¹ç‚¹ï¼š**
1. å°† `ChatHistory` æ›¿æ¢ä¸º `CompositeMemoryService`
2. é›†æˆ RAG ä¸Šä¸‹æ–‡æ£€ç´¢
3. æ„å»ºç»Ÿä¸€ promptï¼ˆå·¥ä½œè®°å¿† + RAG + å½“å‰æ¶ˆæ¯ï¼‰

```python
# ä¿®æ”¹å‰
class EnhancedWorkflowChatService:
    def __init__(
        self,
        workflow_id: str,
        llm: ChatOpenAI,
        chat_message_repository: ChatMessageRepository,
        rag_service=None
    ):
        self.chat_history = ChatHistory(workflow_id, chat_message_repository)
        ...

# ä¿®æ”¹å
class EnhancedWorkflowChatService:
    def __init__(
        self,
        workflow_id: str,
        llm: ChatOpenAI,
        composite_memory: CompositeMemoryService,
        rag_service: Optional[RAGService] = None
    ):
        self.workflow_id = workflow_id
        self.memory = composite_memory
        self.rag_service = rag_service
        ...

    async def process_message(
        self,
        workflow: Workflow,
        user_message: str,
        use_rag: bool = True
    ) -> ModificationResult:
        """å¤„ç†æ¶ˆæ¯ï¼ˆMemory + RAG é›†æˆï¼‰"""

        # 1. åŠ è½½å·¥ä½œè®°å¿†ï¼ˆè‡ªåŠ¨å‹ç¼©ï¼‰
        working_memory = self.memory.load_recent(self.workflow_id, last_n=10)
        memory_context = self._format_memory_context(working_memory)

        # 2. æ£€ç´¢ RAG ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        rag_context = ""
        rag_sources = []
        if use_rag and self.rag_service:
            retrieved = await self.rag_service.retrieve_context(
                QueryContext(
                    query=user_message,
                    workflow_id=self.workflow_id,
                    max_context_length=2000,
                    filters={"user_id": self.workflow_id}  # ç”¨æˆ·éš”ç¦»
                )
            )
            rag_context = retrieved.formatted_context
            rag_sources = retrieved.sources

        # 3. æ„å»ºæœ€ç»ˆ prompt
        system_prompt = self._build_system_prompt(workflow, memory_context, rag_context)

        # 4. è°ƒç”¨ LLM
        response = await self.llm.ainvoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_message)
        ])

        # 5. åº”ç”¨ä¿®æ”¹
        # ... (ç°æœ‰é€»è¾‘)

        # 6. ä¿å­˜åˆ°è®°å¿†ï¼ˆåŒå†™ï¼‰
        user_msg = ChatMessage.create(self.workflow_id, user_message, is_user=True)
        ai_msg = ChatMessage.create(self.workflow_id, ai_reply, is_user=False)

        self.memory.append(user_msg)
        self.memory.append(ai_msg)

        return ModificationResult(
            success=True,
            ai_message=ai_reply,
            rag_sources=rag_sources,
            ...
        )
```

**TDD æ­¥éª¤ï¼š**
1. å†™æµ‹è¯•ï¼ˆREDï¼‰ï¼š`tests/integration/test_workflow_chat_with_composite_memory.py`
   - æµ‹è¯•å•è½®å¯¹è¯
   - æµ‹è¯•å¤šè½®å¯¹è¯ï¼ˆè®°å¿†å»¶ç»­ï¼‰
   - æµ‹è¯• RAG ä¸Šä¸‹æ–‡æ³¨å…¥
   - æµ‹è¯•ç¼“å­˜å‘½ä¸­/æœªå‘½ä¸­
2. å®ç°ï¼ˆGREENï¼‰
3. é‡æ„ï¼ˆREFACTORï¼‰

---

### Phase 5: ç›‘æ§ä¸ APIï¼ˆ2 æ–‡ä»¶ï¼‰

#### 5.1 ç›‘æ§ API

**æ–‡ä»¶ï¼š** `src/interfaces/api/routes/memory_metrics.py`

```python
from fastapi import APIRouter, Depends
from src.interfaces.api.dependencies.memory import get_composite_memory_service

router = APIRouter(prefix="/api/memory", tags=["memory"])

@router.get("/metrics/{workflow_id}")
async def get_memory_metrics(
    workflow_id: str,
    memory_service = Depends(get_composite_memory_service)
):
    """è·å–å†…å­˜ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    metrics = memory_service.get_metrics()

    return {
        "workflow_id": workflow_id,
        "cache_hit_rate": metrics.cache_hit_rate,
        "fallback_count": metrics.fallback_count,
        "avg_compression_ratio": metrics.compression_ratio,
        "avg_fallback_time_ms": metrics.avg_fallback_time_ms,
        "last_updated": metrics.last_updated.isoformat()
    }

@router.post("/cache/invalidate/{workflow_id}")
async def invalidate_cache(
    workflow_id: str,
    memory_service = Depends(get_composite_memory_service)
):
    """æ‰‹åŠ¨å¤±æ•ˆç¼“å­˜"""
    memory_service._cache.invalidate(workflow_id)
    return {"status": "invalidated", "workflow_id": workflow_id}
```

#### 5.2 ä¾èµ–æ³¨å…¥

**æ–‡ä»¶ï¼š** `src/interfaces/api/dependencies/memory.py`

```python
from functools import lru_cache
from src.application.services.composite_memory_service import CompositeMemoryService
from src.infrastructure.memory.database_memory_store import DatabaseMemoryStore
from src.infrastructure.memory.in_memory_cache import InMemoryCache
from src.infrastructure.memory.tfidf_compressor import TFIDFCompressor
from src.interfaces.api.dependencies.database import get_db_session

@lru_cache()
def get_in_memory_cache() -> InMemoryCache:
    """å…¨å±€å•ä¾‹ç¼“å­˜"""
    return InMemoryCache(ttl_seconds=900, max_workflows=1000)

def get_composite_memory_service(session = Depends(get_db_session)):
    """åˆ›å»ºç»„åˆå¼å†…å­˜æœåŠ¡"""
    repository = SQLAlchemyChatMessageRepository(session)
    db_store = DatabaseMemoryStore(repository)
    cache = get_in_memory_cache()
    compressor = TFIDFCompressor()

    return CompositeMemoryService(db_store, cache, compressor)
```

---

### Phase 6: çœŸå®åœºæ™¯é›†æˆæµ‹è¯•ï¼ˆ1 æ–‡ä»¶ï¼‰

**æ–‡ä»¶ï¼š** `tests/integration/test_memory_rag_real_scenario.py`

```python
import pytest
from datetime import datetime, timedelta

class TestMemoryRAGRealScenario:
    """çœŸå®åœºæ™¯æµ‹è¯•ï¼ˆä¸æ˜¯ä¸ºäº†é€šè¿‡è€Œé€šè¿‡ï¼‰"""

    @pytest.mark.asyncio
    async def test_user_builds_workflow_with_conversation_memory(self):
        """
        åœºæ™¯ï¼šç”¨æˆ·é€šè¿‡å¤šè½®å¯¹è¯é€æ­¥æ„å»ºå·¥ä½œæµ

        éªŒè¯ç‚¹ï¼š
        1. ç¬¬ä¸€è½®ï¼šç”¨æˆ·è¯´"åˆ›å»ºä¸€ä¸ª HTTP èŠ‚ç‚¹"
        2. ç¬¬äºŒè½®ï¼šç”¨æˆ·è¯´"å†åŠ ä¸€ä¸ª LLM èŠ‚ç‚¹è¿æ¥åˆ°å®ƒ"ï¼ˆéœ€è¦è®°ä½ç¬¬ä¸€è½®ï¼‰
        3. ç¬¬ä¸‰è½®ï¼šç¼“å­˜è¿‡æœŸï¼Œç³»ç»Ÿè‡ªåŠ¨å›æº¯åˆ°æ•°æ®åº“
        4. ç¬¬å››è½®ï¼šç”¨æˆ·è¯´"æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åšäº†ä»€ä¹ˆ"ï¼ˆæµ‹è¯•æœç´¢åŠŸèƒ½ï¼‰
        """
        # å®ç°å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•
        ...

    @pytest.mark.asyncio
    async def test_rag_personal_knowledge_isolation(self):
        """
        åœºæ™¯ï¼šå¤šç”¨æˆ·ä½¿ç”¨ä¸ªäººçŸ¥è¯†åº“

        éªŒè¯ç‚¹ï¼š
        1. ç”¨æˆ· A ä¸Šä¼ æ–‡æ¡£"å¦‚ä½•ä½¿ç”¨ Redis"
        2. ç”¨æˆ· B ä¸Šä¼ æ–‡æ¡£"å¦‚ä½•ä½¿ç”¨ MongoDB"
        3. ç”¨æˆ· A è¯¢é—®"ç¼“å­˜æ€ä¹ˆç”¨" â†’ åº”è¿”å› Redis æ–‡æ¡£ï¼ˆä¸è¿”å› MongoDBï¼‰
        4. ç”¨æˆ· B è¯¢é—®"æ•°æ®åº“æ€ä¹ˆé€‰" â†’ åº”è¿”å› MongoDB æ–‡æ¡£ï¼ˆä¸è¿”å› Redisï¼‰
        """
        ...

    @pytest.mark.asyncio
    async def test_cache_performance_under_high_load(self):
        """
        åœºæ™¯ï¼šé«˜å¹¶å‘åœºæ™¯ä¸‹çš„ç¼“å­˜æ€§èƒ½

        éªŒè¯ç‚¹ï¼š
        1. æ¨¡æ‹Ÿ 100 ä¸ªå¹¶å‘ workflow
        2. æ¯ä¸ª workflow 10 è½®å¯¹è¯
        3. éªŒè¯ç¼“å­˜å‘½ä¸­ç‡ > 80%
        4. éªŒè¯å¹³å‡å“åº”æ—¶é—´ < 200ms
        """
        ...

    @pytest.mark.asyncio
    async def test_memory_compression_effectiveness(self):
        """
        åœºæ™¯ï¼šé•¿å¯¹è¯å‹ç¼©æ•ˆæœ

        éªŒè¯ç‚¹ï¼š
        1. ç”¨æˆ·è¿›è¡Œ 50 è½®å¯¹è¯ï¼ˆè¶…è¿‡ token é™åˆ¶ï¼‰
        2. ç³»ç»Ÿè‡ªåŠ¨å‹ç¼©åˆ° 4000 tokens
        3. éªŒè¯é‡è¦ä¿¡æ¯ï¼ˆå¦‚èŠ‚ç‚¹åˆ›å»ºå‘½ä»¤ï¼‰è¢«ä¿ç•™
        4. éªŒè¯ä½ä»·å€¼æ¶ˆæ¯ï¼ˆå¦‚"å¥½çš„"ã€"è°¢è°¢"ï¼‰è¢«ç§»é™¤
        """
        ...
```

---

## ğŸ“Š å®æ–½é¡ºåºæ€»ç»“ï¼ˆTDD ä¸¥æ ¼æ‰§è¡Œï¼‰

| Phase | ä»»åŠ¡ | æ–‡ä»¶æ•° | TDD æ­¥éª¤ | é¢„è®¡æ—¶é—´ |
|-------|------|--------|---------|---------|
| 1 | Domain Ports | 2 | REDâ†’GREENâ†’REFACTOR | 30min |
| 2 | Infrastructure Adapters | 3 | REDâ†’GREENâ†’REFACTOR | 90min |
| 3 | Application Composite Service | 1 | REDâ†’GREENâ†’REFACTOR | 60min |
| 4 | Integration to Chat Flow | 1 | REDâ†’GREENâ†’REFACTOR | 45min |
| 5 | Monitoring & API | 2 | REDâ†’GREENâ†’REFACTOR | 30min |
| 6 | Real Scenario Tests | 1 | REDâ†’GREENâ†’REFACTOR | 60min |
| **æ€»è®¡** | **10 æ–‡ä»¶** | | | **~5 å°æ—¶** |

---

## ğŸš¦ å®æ–½çºªå¾‹

### ä¸¥æ ¼éµå®ˆçš„åŸåˆ™ï¼š

1. **TDD ä¸‰éƒ¨æ›²ï¼š**
   - ğŸ”´ RED: å…ˆå†™å¤±è´¥çš„æµ‹è¯•
   - ğŸŸ¢ GREEN: å®ç°æœ€å°ä»£ç è®©æµ‹è¯•é€šè¿‡
   - ğŸ”µ REFACTOR: ä¼˜åŒ–ä»£ç è´¨é‡

2. **åˆ†æ­¥ç¡®è®¤ï¼š**
   - æ¯å®Œæˆ 1 ä¸ª Phaseï¼Œæš‚åœç­‰å¾…ç”¨æˆ·ç¡®è®¤
   - ç¡®è®¤é€šè¿‡åå†è¿›å…¥ä¸‹ä¸€ Phase

3. **æ¶æ„çº¦æŸï¼š**
   - Domain å±‚ï¼šçº¯ Pythonï¼Œé›¶æ¡†æ¶ä¾èµ–
   - Application å±‚ï¼šä¸šåŠ¡ç¼–æ’ï¼Œä¸ç›´æ¥æ“ä½œæ•°æ®åº“
   - Infrastructure å±‚ï¼šé€‚é…å™¨å®ç°ï¼Œéš”ç¦»å¤–éƒ¨ä¾èµ–
   - Interface å±‚ï¼šHTTP APIï¼Œä¾èµ–æ³¨å…¥

4. **æµ‹è¯•è¦†ç›–ç‡ï¼š**
   - Domain å±‚ï¼šâ‰¥ 80%
   - Application å±‚ï¼šâ‰¥ 70%
   - Infrastructure å±‚ï¼šâ‰¥ 60%

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶ï¼š
- âœ… ç¼“å­˜å‘½ä¸­ç‡ > 70%ï¼ˆ10 è½®å¯¹è¯åï¼‰
- âœ… å›æº¯è€—æ—¶ < 500ms
- âœ… å‹ç¼©æ¯” 0.3-0.7ï¼ˆåŸå§‹æ¶ˆæ¯çš„ 30%-70%ï¼‰
- âœ… RAG æ–‡æ¡£éš”ç¦»ï¼ˆè·¨ç”¨æˆ·æ— æ³„æ¼ï¼‰
- âœ… åŒå†™åŸå­æ€§ï¼ˆDB å¤±è´¥ â†’ å›æ»šï¼‰

### æ€§èƒ½éªŒæ”¶ï¼š
- âœ… å•æ¬¡ append è€—æ—¶ < 50ms
- âœ… å•æ¬¡ load_recent è€—æ—¶ < 100msï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
- âœ… å•æ¬¡ load_recent è€—æ—¶ < 500msï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
- âœ… å¹¶å‘ 100 è¯·æ±‚æ— å¼‚å¸¸

### ä»£ç è´¨é‡ï¼š
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆpytestï¼‰
- âœ… ç±»å‹æ£€æŸ¥é€šè¿‡ï¼ˆpyrightï¼‰
- âœ… ä»£ç æ ¼å¼åŒ–ï¼ˆruff formatï¼‰
- âœ… æ—  linting é”™è¯¯ï¼ˆruff checkï¼‰

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **ç°æœ‰ä»£ç ï¼š**
  - ChatMessage Entity: `src/domain/entities/chat_message.py`
  - ChatMessageRepository: `src/infrastructure/database/repositories/chat_message_repository.py`
  - RAGService: `src/application/services/rag_service.py`
  - EnhancedWorkflowChatService: `src/domain/services/workflow_chat_service_enhanced.py`

- **æ–‡æ¡£ï¼š**
  - å¼€å‘è§„èŒƒ: `docs/å¼€å‘è§„èŒƒ/00-æ€»ä½“å¼€å‘è§„èŒƒ.md`
  - TDD æŒ‡å—: `docs/å¼€å‘è§„èŒƒ/03-å¼€å‘è¿‡ç¨‹æŒ‡å¯¼.md`
  - CLAUDE.md: é¡¹ç›®æ ¹ç›®å½•

---

**æœ€åæ›´æ–°ï¼š** 2025-11-30
**çŠ¶æ€ï¼š** å¾…ç”¨æˆ·ç¡®è®¤ âœ‹
**ä¸‹ä¸€æ­¥ï¼š** Phase 1 - Domain å±‚æ¥å£å®šä¹‰
