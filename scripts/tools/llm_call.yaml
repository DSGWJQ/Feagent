# LLM è°ƒç”¨å·¥å…·é…ç½®
# ç”¨äºè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹å¤„ç†æ–‡æœ¬

name: llm_call
description: |
  è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚
  æ”¯æŒå¤šç§ LLM æä¾›å•†ï¼ˆOpenAIã€DeepSeekã€Qwen ç­‰ï¼‰ã€‚
  å¯é…ç½®æ¨¡å‹å‚æ•°å¦‚æ¸©åº¦ã€æœ€å¤§ Token æ•°ç­‰ã€‚
category: ai
version: "1.0.0"
author: system
tags:
  - ai
  - llm
  - chat
  - text-generation
icon: "ğŸ¤–"
shareable_scope: public

entry:
  type: builtin
  handler: llm_call

parameters:
  - name: provider
    type: string
    description: LLM æä¾›å•†
    required: true
    enum:
      - openai
      - deepseek
      - qwen
      - anthropic
      - ollama

  - name: model
    type: string
    description: æ¨¡å‹åç§°ï¼ˆå¦‚ gpt-4ã€deepseek-chatï¼‰
    required: true

  - name: messages
    type: array
    description: |
      å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ã€‚æ¯æ¡æ¶ˆæ¯åŒ…å« roleï¼ˆsystem/user/assistantï¼‰å’Œ content å­—æ®µã€‚
      ç¤ºä¾‹: [{"role": "user", "content": "Hello!"}]
    required: true

  - name: temperature
    type: number
    description: ç”Ÿæˆæ¸©åº¦ï¼ˆ0-2ï¼‰ï¼Œè¶Šé«˜è¶Šéšæœº
    required: false
    default: 0.7

  - name: max_tokens
    type: number
    description: æœ€å¤§ç”Ÿæˆ Token æ•°
    required: false
    default: 1000

  - name: top_p
    type: number
    description: æ ¸é‡‡æ ·æ¦‚ç‡ï¼ˆ0-1ï¼‰
    required: false
    default: 1.0

  - name: stop
    type: array
    description: åœæ­¢ç”Ÿæˆçš„æ ‡è®°åˆ—è¡¨
    required: false

returns:
  content:
    type: string
    description: ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
  usage:
    type: object
    description: Token ä½¿ç”¨ç»Ÿè®¡
    properties:
      prompt_tokens:
        type: number
        description: è¾“å…¥ Token æ•°
      completion_tokens:
        type: number
        description: è¾“å‡º Token æ•°
      total_tokens:
        type: number
        description: æ€» Token æ•°
  model:
    type: string
    description: å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
  finish_reason:
    type: string
    description: ç”Ÿæˆç»“æŸåŸå› ï¼ˆstop/length/content_filterï¼‰
