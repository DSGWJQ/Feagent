from __future__ import annotations

import argparse
import dataclasses
import datetime as dt
import os
import re
import shutil
import sys
from collections.abc import Iterable
from pathlib import Path


@dataclasses.dataclass(frozen=True)
class Action:
    kind: str  # mkdir | move | copy | rmdir
    src: Path | None = None
    dst: Path | None = None
    reason: str = ""
    risk: bool = False


@dataclasses.dataclass(frozen=True)
class Rules:
    protected_dirs: set[str]
    high_dirs: set[str]
    merge_dirs: dict[str, Path]  # source dir name (root) -> destination dir (root-relative)
    htmlcov_dst: Path
    test_reports_dir: Path
    coverage_dir: Path
    docs_integration_dir: Path
    docs_plans_dir: Path
    docs_testing_dir: Path
    docs_analysis_dir: Path
    docs_summaries_dir: Path
    docs_references_dir: Path
    data_databases_dir: Path
    data_test_databases_dir: Path
    data_test_data_dir: Path
    data_metrics_dir: Path
    logs_test_coverage_dir: Path
    logs_agent_traces_dir: Path
    tmp_empty_dir: Path
    backup_dir: str
    tmp_dir: str
    stale_dir: Path
    root_keep_files: set[str]
    root_keep_prefixes: tuple[str, ...]
    type_map: dict[str, str]  # extension -> top-level dir


def _now_stamp() -> str:
    return dt.datetime.now().strftime("%Y%m%d_%H%M%S")


def _ts() -> str:
    return dt.datetime.now().strftime("%H:%M:%S")


def _is_under(path: Path, parent: Path) -> bool:
    try:
        path.relative_to(parent)
        return True
    except ValueError:
        return False


def _top_dir(root: Path, path: Path) -> str | None:
    rel = path.relative_to(root)
    parts = rel.parts
    if not parts:
        return None
    return parts[0]


def _safe_rel(root: Path, path: Path) -> str:
    try:
        return str(path.relative_to(root))
    except Exception:
        return str(path)


def _ensure_unique_path(dst: Path) -> Path:
    if not dst.exists():
        return dst
    stem = dst.stem
    suffix = dst.suffix
    parent = dst.parent
    for i in range(1, 10_000):
        candidate = parent / f"{stem}__conflict{i}{suffix}"
        if not candidate.exists():
            return candidate
    raise RuntimeError(f"æ— æ³•ä¸ºç›®æ ‡è·¯å¾„ç”Ÿæˆä¸å†²çªåç§°ï¼š{dst}")


def _looks_like_log_text(path: Path) -> bool:
    try:
        if path.stat().st_size > 1_000_000:
            return False
        sample = path.read_text(encoding="utf-8", errors="ignore")[:4096]
    except Exception:
        return False
    patterns = [
        r"\b\d{4}-\d{2}-\d{2}\b",
        r"\b\d{2}:\d{2}:\d{2}\b",
        r"\[\d{2}:\d{2}:\d{2}\]",
    ]
    return any(re.search(p, sample) for p in patterns)


def _is_root_keep(rules: Rules, root: Path, path: Path) -> bool:
    rel = path.relative_to(root)
    if len(rel.parts) != 1:
        return False
    name = rel.name
    if name in rules.root_keep_files:
        return True
    if name.startswith("."):
        return True
    return any(name.startswith(prefix) for prefix in rules.root_keep_prefixes)


def _is_protected(rules: Rules, root: Path, path: Path) -> bool:
    top = _top_dir(root, path)
    return top is not None and top in rules.protected_dirs


def _is_high_importance(rules: Rules, root: Path, path: Path) -> bool:
    top = _top_dir(root, path)
    return top is not None and top in rules.high_dirs


def _iter_tree(root: Path, rules: Rules) -> Iterable[Path]:
    for current_dir, dirnames, filenames in os.walk(root):
        current = Path(current_dir)
        if current == root:
            pass
        else:
            top = _top_dir(root, current)
            if top in rules.protected_dirs:
                dirnames[:] = []
                continue

        dirnames[:] = [d for d in dirnames if d not in rules.protected_dirs and d != "__pycache__"]
        for name in filenames:
            yield current / name


def _classify_root_file(
    root: Path, rules: Rules, path: Path, mode: str
) -> tuple[Path | None, str] | None:
    if mode == "safe":
        return None
    if not path.is_file():
        return None
    if _is_root_keep(rules, root, path):
        return None

    name_lower = path.name.lower()

    # å·¥å…·/å·¥ç¨‹æ ¹ç›®å½•çº¦å®šï¼šä¿æŒåŸä½
    if path.name == "pyrightconfig.json":
        return None

    # æ ¹ç›®å½•â€œæ•£è½æ–‡ä»¶â€ä»…åšæœ‰é™å½’ä½ï¼šä»¥ä½ ç»™çš„æ¸…å•ä¸ºå‡†
    if name_lower == ".coverage":
        return (root / rules.stale_dir / path.name, "ä¸´æ—¶è¦†ç›–ç‡")
    if name_lower in {"coverage_output.txt", "full_coverage.txt", "test_coverage_output.txt"}:
        return (root / rules.logs_test_coverage_dir / path.name, "è¦†ç›–ç‡æ—¥å¿—")
    if name_lower == "coverage.json":
        return (root / rules.data_metrics_dir / path.name, "è¦†ç›–ç‡æ•°æ®")
    if name_lower == "agent_data.db":
        return (root / rules.data_databases_dir / path.name, "æ•°æ®åº“æ–‡ä»¶")
    if name_lower == "test_integration.db":
        return (root / rules.data_test_databases_dir / path.name, "æµ‹è¯•æ•°æ®åº“")
    if name_lower == "test_create_agent.json":
        return (root / rules.data_test_data_dir / path.name, "æµ‹è¯•æ•°æ®")
    if name_lower == "leaf":
        return (root / rules.logs_agent_traces_dir / "Leaf.jsonl", "è¿è¡Œè¿½è¸ª")
    if name_lower == "nul":
        # Windows ä¿ç•™åï¼šè½ç›˜æ—¶æ”¹åé¿å…åç»­æ— æ³•è®¿é—®
        return (root / rules.tmp_empty_dir / "nul.zero", "ç©ºæ–‡ä»¶")

    # å…¶å®ƒæ ¹ç›®å½• md/txt ç”±â€œå›ºå®šæ˜ å°„è¡¨â€å¤„ç†ï¼ˆè§ build_planï¼‰

    return None


def _stale_candidate(rules: Rules, root: Path, path: Path, stale_days: int) -> bool:
    if _is_protected(rules, root, path):
        return False
    if path.is_dir():
        return False

    # ä»…å¯¹ tmp/ å†…ã€æˆ–æ ¹ç›®å½•æ˜æ˜¾ä¸´æ—¶æ–‡ä»¶åšâ€œè¿‡æ—¶â€åˆ¤å®šï¼Œé¿å…è¯¯ä¼¤é«˜é‡è¦åº¦ç›®å½•
    rel = path.relative_to(root)
    in_tmp = rel.parts and rel.parts[0] == rules.tmp_dir
    in_root = len(rel.parts) == 1

    name_lower = path.name.lower()
    if in_root and not re.search(r"\.(tmp|cache|swp)$", name_lower):
        return False

    if not (in_tmp or in_root):
        return False

    if _is_under(path, root / rules.stale_dir):
        return False

    try:
        st = path.stat()
    except Exception:
        return False

    now = dt.datetime.now().timestamp()
    mtime_days = (now - st.st_mtime) / 86400
    atime_days = (now - st.st_atime) / 86400

    name_hit = any(token in name_lower for token in ("tmp", "temp", "~$", "cache_", "old_"))
    zero_size = st.st_size == 0 and path.name not in {".gitkeep"}
    time_hit = (mtime_days > stale_days) and (atime_days > 30)

    return time_hit or name_hit or zero_size


def _plan_merge_dir(root: Path, src_dirname: str, dst_dir: Path) -> list[Action]:
    src_dir = root / src_dirname
    if not src_dir.exists() or not src_dir.is_dir():
        return []

    actions: list[Action] = []
    for item in src_dir.rglob("*"):
        if item.is_dir():
            continue
        rel = item.relative_to(src_dir)
        dst = root / dst_dir / rel
        actions.append(Action(kind="move", src=item, dst=dst, reason="ç›®å½•åˆå¹¶"))

    return actions


def _plan_htmlcov(root: Path, rules: Rules) -> list[Action]:
    src_dir = root / "htmlcov"
    if not src_dir.exists() or not src_dir.is_dir():
        return []
    actions: list[Action] = []
    for item in src_dir.rglob("*"):
        if item.is_dir():
            continue
        rel = item.relative_to(src_dir)
        dst = root / rules.htmlcov_dst / rel
        actions.append(Action(kind="move", src=item, dst=dst, reason="è¦†ç›–ç‡æŠ¥å‘Š"))
    return actions


def _plan_type_mapping(root: Path, rules: Rules, mode: str) -> list[Action]:
    if mode == "safe":
        return []

    actions: list[Action] = []
    for path in _iter_tree(root, rules):
        if _is_protected(rules, root, path):
            continue
        if path.is_dir():
            continue
        if _is_root_keep(rules, root, path):
            continue
        if _top_dir(root, path) in rules.merge_dirs:
            continue
        if _top_dir(root, path) == "htmlcov":
            continue

        ext = path.suffix.lower()
        target_top = None
        if ext == ".txt" and mode == "aggressive" and _looks_like_log_text(path):
            # æå°‘æ•°æƒ…å†µä¸‹ï¼Œ.txt å¯èƒ½æ˜¯ç»“æ„åŒ–æ—¥å¿—ï¼›ä»…åœ¨ aggressive æ¨¡å¼å¯ç”¨
            target_top = "logs"
        elif ext:
            target_top = rules.type_map.get(ext)
        if not target_top:
            continue

        # ä¿å®ˆï¼šé¿å…æŠŠ .py éšæ„æŒªå‡ºå·¥ç¨‹ç»“æ„
        if ext == ".py" and mode != "aggressive":
            continue

        # é¿å…æŠŠ docs é‡Œçš„æ–‡æ¡£å†æŒªæ¥æŒªå»
        if _top_dir(root, path) in {
            "docs",
            "scripts",
            "tests",
            "config",
            "data",
            "logs",
            "uploads",
            "backup",
        }:
            continue

        rel = path.relative_to(root)
        dst = root / target_top / rel.name
        risk = target_top in rules.high_dirs
        actions.append(Action(kind="move", src=path, dst=dst, reason="ç±»å‹æ˜ å°„", risk=risk))

    return actions


def _apply_actions(
    root: Path,
    rules: Rules,
    actions: list[Action],
    *,
    dry_run: bool,
    prune_empty: bool,
    log_file: Path | None,
    make_rollback: bool,
    verbose: bool,
) -> dict[str, int]:
    counts = {"move": 0, "mkdir": 0, "copy": 0, "rmdir": 0, "skip": 0, "conflict_rename": 0}
    moved_pairs: list[tuple[Path, Path]] = []

    log_fp = None
    if log_file is not None:
        try:
            log_file.parent.mkdir(parents=True, exist_ok=True)
            log_fp = log_file.open("a", encoding="utf-8")
        except Exception:
            log_fp = None

    def log(line: str, *, to_console: bool = False) -> None:
        if to_console:
            print(line)
        if log_fp is not None:
            try:
                log_fp.write(line + "\n")
                log_fp.flush()
            except Exception:
                pass

    def note_action(action: Action, src: Path, dst: Path) -> None:
        warn = "âš ï¸ " if action.risk else ""
        line = f"[{_ts()}] {warn}{_safe_rel(root, src)} â†’ {_safe_rel(root, dst)} ({action.reason})"
        # æ§åˆ¶å°é»˜è®¤ç²¾ç®€ï¼šä»…è¾“å‡ºé£é™©é¡¹/å†²çªé¡¹ï¼›å®Œæ•´æ˜ç»†å†™å…¥æ—¥å¿—æ–‡ä»¶
        log(line, to_console=verbose or action.risk)

    def maybe_backup_config(src: Path, dst: Path) -> None:
        if dry_run:
            return
        # è§¦åŠ config çš„ç§»åŠ¨ï¼šæ— è®ºæºåœ¨ root è¿˜æ˜¯ config/ï¼Œéƒ½åœ¨ config/backup/ ç•™ä¸€ä»½
        if _top_dir(root, src) != "config" and _top_dir(root, dst) != "config":
            return
        try:
            if _top_dir(root, src) == "config":
                rel_in_config = src.relative_to(root / "config")
            else:
                rel_in_config = Path("root") / src.name
        except Exception:
            rel_in_config = Path("root") / src.name
        backup_root = root / "config" / "backup"
        stamp = _now_stamp()
        backup_path = backup_root / rel_in_config
        backup_path = backup_path.with_name(f"{backup_path.name}.{stamp}.bak")
        backup_path.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(str(src), str(backup_path))

    for action in actions:
        if action.kind == "move":
            assert action.src is not None and action.dst is not None
            src = action.src
            dst = action.dst

            src_str = str(src)
            dst_str = str(dst)
            # Windows ä¿ç•™æ–‡ä»¶åï¼ˆå¦‚ nulï¼‰éœ€è¦ \\?\ å‰ç¼€æ‰èƒ½è®¿é—®
            if os.name == "nt" and src.name.lower() in {"nul"}:
                src_str = f"\\\\?\\{str(src.resolve())}"

            if not os.path.exists(src_str):
                counts["skip"] += 1
                continue

            if action.risk and action.dst is not None:
                maybe_backup_config(src, action.dst)

            dst.parent.mkdir(parents=True, exist_ok=True) if not dry_run else None
            resolved = dst
            if dst.exists():
                resolved = _ensure_unique_path(dst)
                counts["conflict_rename"] += 1
                log(
                    f"[{_ts()}] âš ï¸ ç›®æ ‡å†²çªï¼š{_safe_rel(root, dst)} â†’ {_safe_rel(root, resolved)} (è‡ªåŠ¨é‡å‘½å)",
                    to_console=True,
                )
                dst_str = str(resolved)

            note_action(action, src, resolved)
            if not dry_run:
                shutil.move(src_str, dst_str)
            counts["move"] += 1
            moved_pairs.append((src, resolved))

        elif action.kind == "mkdir":
            assert action.dst is not None
            if action.dst.exists():
                counts["skip"] += 1
                continue
            log(f"[{_ts()}] {_safe_rel(root, action.dst)} (åˆ›å»ºç›®å½•)", to_console=verbose)
            if not dry_run:
                action.dst.mkdir(parents=True, exist_ok=True)
            counts["mkdir"] += 1

        elif action.kind == "copy":
            assert action.src is not None and action.dst is not None
            if not action.src.exists():
                counts["skip"] += 1
                continue
            action.dst.parent.mkdir(parents=True, exist_ok=True) if not dry_run else None
            log(
                f"[{_ts()}] {_safe_rel(root, action.src)} â†’ {_safe_rel(root, action.dst)} ({action.reason})",
                to_console=verbose,
            )
            if not dry_run:
                shutil.copy2(str(action.src), str(action.dst))
            counts["copy"] += 1

        elif action.kind == "rmdir":
            assert action.src is not None
            if not action.src.exists():
                counts["skip"] += 1
                continue
            log(f"[{_ts()}] {_safe_rel(root, action.src)} (ç§»é™¤ç©ºç›®å½•)", to_console=verbose)
            if not dry_run:
                try:
                    action.src.rmdir()
                except OSError:
                    counts["skip"] += 1
                    continue
            counts["rmdir"] += 1

    if log_fp is not None:
        try:
            log_fp.close()
        except Exception:
            pass

    if make_rollback:
        _write_rollback_scripts(root, moved_pairs, dry_run=dry_run)

    if prune_empty and not dry_run:
        _prune_empty_dirs(root, rules, log=print)

    return counts


def _write_rollback_scripts(
    root: Path, moved_pairs: list[tuple[Path, Path]], *, dry_run: bool
) -> None:
    stamp = _now_stamp()
    sh_path = root / "logs" / f"undo_organization_{stamp}.sh"
    ps_path = root / "logs" / f"undo_organization_{stamp}.ps1"

    # åå‘æ‰§è¡Œï¼šä» dst ç§»å› srcã€‚æŒ‰é€†åºæ›´å®‰å…¨ã€‚
    lines_sh = ["#!/usr/bin/env bash", "set -euo pipefail", ""]
    lines_ps = ["Set-StrictMode -Version Latest", "$ErrorActionPreference = 'Stop'", ""]
    for src, dst in reversed(moved_pairs):
        lines_sh.append(f"mkdir -p {shlex_quote(str(src.parent))}")
        lines_sh.append(f"mv {shlex_quote(str(dst))} {shlex_quote(str(src))}")
        lines_ps.append(
            f"New-Item -ItemType Directory -Force -Path {ps_quote(str(src.parent))} | Out-Null"
        )
        lines_ps.append(
            f"Move-Item -Force -Path {ps_quote(str(dst))} -Destination {ps_quote(str(src))}"
        )

    if dry_run:
        return

    sh_path.parent.mkdir(parents=True, exist_ok=True)
    sh_path.write_text("\n".join(lines_sh) + "\n", encoding="utf-8")
    ps_path.write_text("\n".join(lines_ps) + "\n", encoding="utf-8")


def shlex_quote(s: str) -> str:
    if not s:
        return "''"
    if re.fullmatch(r"[A-Za-z0-9_./:-]+", s):
        return s
    return "'" + s.replace("'", "'\"'\"'") + "'"


def ps_quote(s: str) -> str:
    return "'" + s.replace("'", "''") + "'"


def _prune_empty_dirs(root: Path, rules: Rules, *, log) -> None:
    protected = {root / d for d in rules.protected_dirs}
    protected |= {root / d for d in rules.high_dirs}
    # æ³¨æ„ï¼šmerge æºç›®å½•ä¸ htmlcov/ è‹¥å·²å˜ç©ºï¼Œå…è®¸åœ¨ prune-empty ä¸­æ¸…ç†
    protected |= {root / rules.tmp_dir, root / rules.backup_dir}
    protected |= {root}

    for dirpath, _dirnames, _ in os.walk(root, topdown=False):
        p = Path(dirpath)
        if p in protected:
            continue
        if _is_protected(rules, root, p):
            continue
        try:
            if not any(p.iterdir()):
                log(f"[{_ts()}] {_safe_rel(root, p)} (ç§»é™¤ç©ºç›®å½•)")
                p.rmdir()
        except Exception:
            continue


def _build_rules() -> Rules:
    protected = {
        "src",
        "web",
        "definitions",
        "typings",
        ".git",
        ".venv",
        "venv",
        "node_modules",
        ".pytest_cache",
        ".ruff_cache",
        ".mypy_cache",
        ".pre-commit-cache",
        ".obsidian",
        ".vscode",
    }
    high = {"config", "data", "logs", "uploads", "scripts", "tests", "backup"}
    merge = {
        "tools": Path("scripts") / "tools",
        "notebooks": Path("docs") / "notebooks",
        "reports": Path("docs") / "reports",
    }
    htmlcov_dst = Path("docs") / "test_reports" / "coverage"
    test_reports_dir = Path("docs") / "test_reports"
    coverage_dir = Path("docs") / "test_reports" / "coverage"
    docs_integration_dir = Path("docs") / "integration"
    docs_plans_dir = Path("docs") / "plans"
    docs_testing_dir = Path("docs") / "testing"
    docs_analysis_dir = Path("docs") / "analysis"
    docs_summaries_dir = Path("docs") / "summaries"
    docs_references_dir = Path("docs") / "references"
    data_databases_dir = Path("data") / "databases"
    data_test_databases_dir = Path("data") / "test_databases"
    data_test_data_dir = Path("data") / "test_data"
    data_metrics_dir = Path("data") / "metrics"
    logs_test_coverage_dir = Path("logs") / "test_coverage"
    logs_agent_traces_dir = Path("logs") / "agent_traces"
    tmp_empty_dir = Path("tmp") / "_empty"
    root_keep = {
        "pyproject.toml",
        "README.md",
        "LICENSE",
        ".gitignore",
        ".env",
        ".env.example",
        "alembic.ini",
        "pyrightconfig.json",
        "CLAUDE.md",
    }
    root_keep_prefixes: tuple[str, ...] = ()

    type_map = {}
    for ext in (".yml", ".yaml", ".json", ".ini", ".toml", ".env", ".cfg", ".conf", ".properties"):
        type_map[ext] = "config"
    for ext in (".sh", ".bat", ".ps1", ".py"):
        type_map[ext] = "scripts"
    for ext in (".csv", ".jsonl", ".parquet", ".db", ".sqlite", ".xlsx", ".h5", ".feather"):
        type_map[ext] = "data"
    for ext in (".md", ".pdf", ".docx", ".pptx", ".ipynb", ".html", ".rst", ".tex"):
        type_map[ext] = "docs"
    for ext in (".log",):
        type_map[ext] = "logs"

    return Rules(
        protected_dirs=protected,
        high_dirs=high,
        merge_dirs=merge,
        htmlcov_dst=htmlcov_dst,
        test_reports_dir=test_reports_dir,
        coverage_dir=coverage_dir,
        docs_integration_dir=docs_integration_dir,
        docs_plans_dir=docs_plans_dir,
        docs_testing_dir=docs_testing_dir,
        docs_analysis_dir=docs_analysis_dir,
        docs_summaries_dir=docs_summaries_dir,
        docs_references_dir=docs_references_dir,
        data_databases_dir=data_databases_dir,
        data_test_databases_dir=data_test_databases_dir,
        data_test_data_dir=data_test_data_dir,
        data_metrics_dir=data_metrics_dir,
        logs_test_coverage_dir=logs_test_coverage_dir,
        logs_agent_traces_dir=logs_agent_traces_dir,
        tmp_empty_dir=tmp_empty_dir,
        backup_dir="backup",
        tmp_dir="tmp",
        stale_dir=Path("tmp") / "_stale",
        root_keep_files=root_keep,
        root_keep_prefixes=root_keep_prefixes,
        type_map=type_map,
    )


def _summarize(
    root: Path,
    rules: Rules,
    actions: list[Action],
    counts: dict[str, int] | None,
    *,
    dry_run: bool,
    log_file: Path | None,
) -> None:
    merge_items = []
    for src, dst in rules.merge_dirs.items():
        if (root / src).exists():
            merge_items.append((src, str(dst)))
    if (root / "htmlcov").exists():
        merge_items.append(("htmlcov", str(rules.htmlcov_dst)))

    print()
    title = "æ–‡ä»¶æ•´ç†é¢„è§ˆ" if dry_run else "æ–‡ä»¶æ•´ç†å®Œæˆ"
    print(f"ğŸ“ {title} | é¡¹ç›®ï¼š{root.name}")
    print("â”œâ”€â”€ ğŸ§© ç»“æ„ä¼˜åŒ–")
    if merge_items:
        for src, dst in merge_items:
            print(f"â”‚ â”œâ”€â”€ {src}/ â†’ {dst}/")
    else:
        print("â”‚ â””â”€â”€ ï¼ˆæ— ï¼‰")

    total_actions = len([a for a in actions if a.kind == "move"])
    print("â”œâ”€â”€ ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
    print(f"â”‚ â”œâ”€ è®¡åˆ’å˜æ›´ï¼š{total_actions} é¡¹")
    if counts:
        print(
            "â”‚ â”œâ”€ æ‰§è¡Œè®¡æ•°ï¼š"
            f"move={counts['move']} mkdir={counts['mkdir']} copy={counts['copy']} "
            f"conflict_rename={counts['conflict_rename']} skip={counts['skip']}"
        )
    print(f"â”‚ â””â”€ è·³è¿‡ä¿æŠ¤ï¼š{', '.join(sorted({'src','web','definitions','typings'}))}")

    important = [a for a in actions if a.risk]
    if important:
        print("â”œâ”€â”€ âš ï¸ é‡è¦æç¤º")
        print(f"â”‚ â””â”€ é«˜é‡è¦åº¦ç›¸å…³æ“ä½œï¼š{len(important)} é¡¹ï¼ˆå»ºè®®å…ˆ dry-run æ£€æŸ¥ï¼‰")

    if log_file is not None:
        print(f"â””â”€â”€ ğŸ§¾ è¯¦ç»†æ—¥å¿—ï¼š{_safe_rel(root, log_file)}")
    else:
        print("â””â”€â”€ ğŸ§¾ è¯¦ç»†æ—¥å¿—ï¼šæœªå†™å…¥æ–‡ä»¶ï¼ˆä»…æ§åˆ¶å°ï¼‰")


def build_plan(root: Path, rules: Rules, *, mode: str, stale_days: int) -> list[Action]:
    actions: list[Action] = []

    # ç›®å½•åˆå¹¶ï¼ˆä¿æŒç»“æ„ï¼‰ï¼štoolsâ†’scripts/tools, notebooks/reportsâ†’docs/*
    for src, dst in rules.merge_dirs.items():
        actions.extend(_plan_merge_dir(root, src, dst))

    # htmlcov ç‰¹æ®Šå¤„ç†ï¼šè¿ç§»åˆ° docs/test_reports/coverage/
    actions.extend(_plan_htmlcov(root, rules))

    def add_fixed_move(src: Path, dst: Path, reason: str) -> None:
        if not src.exists():
            return
        actions.append(Action(kind="move", src=src, dst=dst, reason=reason))

    def add_fixed_move_from_candidates(
        candidates: list[Path],
        dst: Path,
        reason: str,
    ) -> None:
        for c in candidates:
            if c.exists():
                actions.append(Action(kind="move", src=c, dst=dst, reason=reason))
                return

    # ç›®å½•ç»“æ„ï¼ˆdocs/*ã€data/*ã€logs/*ã€tmp/*ï¼‰æŒ‰ç§»åŠ¨ç›®æ ‡è‡ªåŠ¨åˆ›å»º
    # 1) æ ¹ç›®å½•æ•£è½æ–‡ä»¶ï¼ˆæŒ‰æ¸…å•å½’ä½ï¼‰
    # æ ¹ç›®å½•æ•£è½æ–‡ä»¶ï¼šmarkdown/json/txt ç­‰å½’ä½
    for item in root.iterdir():
        if not item.is_file():
            continue
        classified = _classify_root_file(root, rules, item, mode)
        if not classified:
            continue
        dst, reason = classified
        if dst is None:
            continue
        actions.append(Action(kind="move", src=item, dst=dst, reason=reason))

    # 2) ä¹‹å‰å·²å½’æ¡£åˆ° docs/test_reports/coverage çš„è¦†ç›–ç‡è¾“å‡ºï¼šæŒ‰æ–°è§„åˆ™æŒªåˆ° data/logs
    add_fixed_move_from_candidates(
        [root / rules.coverage_dir / "coverage.json", root / "coverage.json"],
        root / rules.data_metrics_dir / "coverage.json",
        "è¦†ç›–ç‡æ•°æ®",
    )
    for name in ("coverage_output.txt", "full_coverage.txt", "test_coverage_output.txt"):
        add_fixed_move_from_candidates(
            [root / rules.coverage_dir / name, root / name],
            root / rules.logs_test_coverage_dir / name,
            "è¦†ç›–ç‡æ—¥å¿—",
        )

    # 2.1) root ä¸‹çš„ .coverageï¼šå³ä½¿æ˜¯ dotfileï¼Œä¹ŸæŒ‰è§„åˆ™ç§»åˆ° tmp/_stale/
    add_fixed_move(root / ".coverage", root / rules.stale_dir / ".coverage", "ä¸´æ—¶è¦†ç›–ç‡")

    # 2.2) Windows ä¿ç•™åæ–‡ä»¶ nulï¼šç”¨ \\?\ æ‰èƒ½è®¿é—®çš„æƒ…å†µä¹ŸæŒ‰è§„åˆ™ç§»åˆ° tmp/_empty/
    if os.name == "nt":
        nul_path = root / "nul"
        nul_alt = f"\\\\?\\{str(nul_path.resolve())}"
        if os.path.exists(nul_alt):
            actions.append(
                Action(
                    kind="move",
                    src=nul_path,
                    dst=root / rules.tmp_empty_dir / "nul.zero",
                    reason="ç©ºæ–‡ä»¶",
                )
            )

    # 3) æ–‡æ¡£å›ºå®šæ˜ å°„ï¼ˆæŒ‰ä½ ç»™çš„è¡¨ï¼‰
    # æ³¨æ„ï¼šCLAUDE.md æ˜ç¡®ä¸åŠ¨ï¼ˆå·²åœ¨ root_keep_filesï¼‰
    add_fixed_move(
        root / "FRONTEND_INTEGRATION_SUMMARY.md",
        root / rules.docs_integration_dir / "FRONTEND_INTEGRATION_SUMMARY.md",
        "é›†æˆæ–‡æ¡£",
    )
    add_fixed_move(
        root / "MEMORY_RAG_IMPLEMENTATION_PLAN.md",
        root / rules.docs_plans_dir / "MEMORY_RAG_IMPLEMENTATION_PLAN.md",
        "å®æ–½è®¡åˆ’",
    )
    add_fixed_move(
        root / "next_actions_plan.md",
        root / rules.docs_plans_dir / "next_actions_plan.md",
        "è¡ŒåŠ¨è®¡åˆ’",
    )
    add_fixed_move(
        root / "phase2_conversation_agent_plan.md",
        root / rules.docs_plans_dir / "phase2_conversation_agent_plan.md",
        "é˜¶æ®µè®¡åˆ’",
    )
    add_fixed_move(
        root / "MOCK_CODE_PATCHES.md",
        root / rules.docs_testing_dir / "MOCK_CODE_PATCHES.md",
        "æµ‹è¯•æ–‡æ¡£",
    )
    add_fixed_move(
        root / "MOCK_EXTERNAL_SERVICES_ANALYSIS.md",
        root / rules.docs_analysis_dir / "MOCK_EXTERNAL_SERVICES_ANALYSIS.md",
        "åˆ†ææŠ¥å‘Š",
    )
    add_fixed_move(
        root / "MOCK_EXTERNAL_SERVICES_SUMMARY.md",
        root / rules.docs_summaries_dir / "MOCK_EXTERNAL_SERVICES_SUMMARY.md",
        "æ€»ç»“æŠ¥å‘Š",
    )
    add_fixed_move(
        root / "MOCK_QUICK_REFERENCE.md",
        root / rules.docs_references_dir / "MOCK_QUICK_REFERENCE.md",
        "å¿«é€Ÿå‚è€ƒ",
    )
    add_fixed_move(
        root / "PROJECT_RAG_COMPLETION_SUMMARY.md",
        root / rules.docs_summaries_dir / "PROJECT_RAG_COMPLETION_SUMMARY.md",
        "é¡¹ç›®æ€»ç»“",
    )
    add_fixed_move(
        root / "TESTING_ANALYSIS_SUMMARY.md",
        root / rules.docs_testing_dir / "TESTING_ANALYSIS_SUMMARY.md",
        "æµ‹è¯•åˆ†æ",
    )
    add_fixed_move(
        root / "TESTING_DOCUMENTATION_INDEX.md",
        root / rules.docs_testing_dir / "TESTING_DOCUMENTATION_INDEX.md",
        "æµ‹è¯•ç´¢å¼•",
    )
    add_fixed_move(
        root / "TESTING_DOCUMENTS_MANIFEST.txt",
        root / rules.docs_testing_dir / "TESTING_DOCUMENTS_MANIFEST.txt",
        "æµ‹è¯•æ¸…å•",
    )
    add_fixed_move(
        root / "TESTING_EXECUTION_CHECKLIST.md",
        root / rules.docs_testing_dir / "TESTING_EXECUTION_CHECKLIST.md",
        "æ‰§è¡Œæ¸…å•",
    )
    add_fixed_move(
        root / "TESTING_FINAL_REPORT.md",
        root / rules.docs_testing_dir / "TESTING_FINAL_REPORT.md",
        "æœ€ç»ˆæŠ¥å‘Š",
    )
    add_fixed_move(
        root / "TESTING_QUICK_REFERENCE.md",
        root / rules.docs_references_dir / "TESTING_QUICK_REFERENCE.md",
        "æµ‹è¯•å‚è€ƒ",
    )
    add_fixed_move_from_candidates(
        [root / "WORKFLOW_CHAT_API_TEST.md", root / "docs" / "misc" / "WORKFLOW_CHAT_API_TEST.md"],
        root / rules.docs_testing_dir / "WORKFLOW_CHAT_API_TEST.md",
        "APIæµ‹è¯•",
    )

    # 4) test_create_agent.json è‹¥å·²ç§»åˆ° docs/examplesï¼Œåˆ™æŒ‰æ–°è§„åˆ™æŒªåˆ° data/test_data
    add_fixed_move_from_candidates(
        [root / "docs" / "examples" / "test_create_agent.json", root / "test_create_agent.json"],
        root / rules.data_test_data_dir / "test_create_agent.json",
        "æµ‹è¯•æ•°æ®",
    )

    # ç±»å‹æ˜ å°„ï¼ˆå…¨ç›˜ï¼‰ï¼šä»…åœ¨ aggressive æ¨¡å¼å¯ç”¨ï¼Œé¿å…è¯¯ä¼¤ä»“åº“å†…éƒ¨ç»“æ„
    if mode == "aggressive":
        actions.extend(_plan_type_mapping(root, rules, mode))

    # è¿‡æ—¶/ä¸´æ—¶æ–‡ä»¶ï¼šç§»è‡³ tmp/_stale/
    for path in _iter_tree(root, rules):
        if _stale_candidate(rules, root, path, stale_days):
            rel = path.relative_to(root)
            dst = root / rules.stale_dir / rel.name
            actions.append(Action(kind="move", src=path, dst=dst, reason="è¿‡æœŸä¸´æ—¶"))

    # é£é™©æ ‡è®°ï¼šæ¶‰åŠé«˜é‡è¦åº¦ç›®å½•ï¼ˆæºæˆ–ç›®æ ‡ï¼‰
    marked: list[Action] = []
    for a in actions:
        if a.kind != "move" or a.src is None or a.dst is None:
            marked.append(a)
            continue
        # é¢å¤–å®‰å…¨é—¸ï¼šä»»ä½•è§¦åŠä¿æŠ¤ç›®å½•çš„åŠ¨ä½œç›´æ¥ä¸¢å¼ƒ
        if (
            _top_dir(root, a.src) in rules.protected_dirs
            or _top_dir(root, a.dst) in rules.protected_dirs
        ):
            continue
        risk = _is_high_importance(rules, root, a.src) or _is_high_importance(rules, root, a.dst)
        marked.append(dataclasses.replace(a, risk=risk or a.risk))

    # å»é‡ï¼šåŒä¸€ src åªä¿ç•™ç¬¬ä¸€æ¡åŠ¨ä½œï¼ˆå‰é¢çš„è§„åˆ™ä¼˜å…ˆçº§æ›´é«˜ï¼‰
    seen_src: set[str] = set()
    uniq: list[Action] = []
    for a in marked:
        if a.kind == "move" and a.src is not None and a.dst is not None:
            key = str(a.src)
            if key in seen_src:
                continue
            seen_src.add(key)
        uniq.append(a)

    return uniq


def main(argv: list[str]) -> int:
    try:
        sys.stdout.reconfigure(encoding="utf-8", errors="replace")  # type: ignore[attr-defined]
        sys.stderr.reconfigure(encoding="utf-8", errors="replace")  # type: ignore[attr-defined]
    except Exception:
        pass

    parser = argparse.ArgumentParser(description="æ™ºèƒ½æ•´ç†é¡¹ç›®æ–‡ä»¶ç»“æ„ï¼ˆæ”¯æŒ dry-run / å›æ»šï¼‰")
    parser.add_argument("--root", type=Path, default=Path.cwd(), help="é¡¹ç›®æ ¹ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰")
    parser.add_argument(
        "--mode",
        choices=["safe", "standard", "aggressive"],
        default="standard",
        help="æ•´ç†åŠ›åº¦ï¼šsafe=ä»…åˆå¹¶/ç‰¹æ®Šç›®å½•ï¼Œstandard=åŠ å°‘é‡ç±»å‹æ˜ å°„ï¼Œaggressive=æ›´ç§¯æç±»å‹æ˜ å°„",
    )
    parser.add_argument("--stale-days", type=int, default=60, help="è¿‡æ—¶æ–‡ä»¶é˜ˆå€¼ï¼ˆé»˜è®¤60å¤©ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…é¢„è§ˆï¼Œä¸æ‰§è¡Œï¼ˆå»ºè®®é»˜è®¤å…ˆè·‘ä¸€æ¬¡ï¼‰")
    parser.add_argument("--apply", action="store_true", help="å®é™…æ‰§è¡Œç§»åŠ¨/åˆ›å»º/å›æ»šè„šæœ¬ç”Ÿæˆ")
    parser.add_argument("--yes", action="store_true", help="é…åˆ --apply ä½¿ç”¨ï¼šç¡®è®¤æ‰§è¡Œæ–‡ä»¶ç§»åŠ¨")
    parser.add_argument("--prune-empty", action="store_true", help="æ‰§è¡Œåæ¸…ç†ç©ºç›®å½•ï¼ˆè°¨æ…ï¼‰")
    parser.add_argument(
        "--log-file",
        type=str,
        default="",
        help="æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼›ç•™ç©º=é»˜è®¤å†™å…¥ logs/ï¼›ä¼  '-'=ä¸å†™æ–‡ä»¶",
    )
    parser.add_argument("--no-rollback", action="store_true", help="ä¸ç”Ÿæˆå›æ»šè„šæœ¬")
    parser.add_argument("--verbose", action="store_true", help="æ§åˆ¶å°è¾“å‡ºæ¯ä¸ªæ“ä½œæ˜ç»†ï¼ˆé»˜è®¤ç²¾ç®€ï¼‰")

    args = parser.parse_args(argv)

    root = args.root.resolve()
    rules = _build_rules()

    if args.apply and args.dry_run:
        print("å‚æ•°å†²çªï¼š--apply ä¸ --dry-run ä¸èƒ½åŒæ—¶ä½¿ç”¨ã€‚")
        return 2
    if args.apply and not args.yes:
        print("å®‰å…¨ä¿æŠ¤ï¼šå®é™…æ‰§è¡Œéœ€è¦åŒæ—¶ä¼ å…¥ --apply --yesã€‚")
        return 2
    dry_run = not args.apply
    if args.dry_run:
        dry_run = True

    if not root.exists() or not root.is_dir():
        print(f"æ ¹ç›®å½•ä¸å­˜åœ¨ï¼š{root}")
        return 2

    if args.log_file.strip() == "-":
        log_file = None
    elif args.log_file.strip():
        log_file = (root / args.log_file).resolve()
    else:
        log_file = root / "logs" / f"file_organize_{_now_stamp()}.log"

    print(f"[{_ts()}] é˜¶æ®µ1/6ï¼šæ‰«æä¸è§„åˆ™åŠ è½½â€¦")
    print(
        f"[{_ts()}] ä¿æŠ¤ç›®å½•ï¼š{', '.join(sorted({'src','web','definitions','typings'}))}ï¼ˆä¸ç§»åŠ¨ã€ä¸æ‰«æå†…å®¹ï¼‰"
    )
    print(f"[{_ts()}] é˜¶æ®µ2/6ï¼šåˆ†ç±»å†³ç­–çŸ©é˜µâ€¦")
    actions = build_plan(root, rules, mode=args.mode, stale_days=args.stale_days)

    print(f"[{_ts()}] é˜¶æ®µ3/6ï¼šæ™ºèƒ½åˆå¹¶ä¸ç‰¹æ®Šç›®å½•å¤„ç†â€¦")
    # è¿™é‡Œçš„åŠ¨ä½œå·²åŒ…å«åˆå¹¶/htmlcov

    print(f"[{_ts()}] é˜¶æ®µ4/6ï¼šå†²çªæ£€æµ‹ä¸æ¸…ç†è§„åˆ’â€¦")
    # å†²çªåœ¨æ‰§è¡Œé˜¶æ®µå¤„ç†ï¼ˆè‡ªåŠ¨é‡å‘½åï¼‰

    print(f"[{_ts()}] é˜¶æ®µ5/6ï¼šæ‰§è¡Œâ€¦({'dry-run' if dry_run else 'apply'})")
    counts = _apply_actions(
        root,
        rules,
        actions,
        dry_run=dry_run,
        prune_empty=args.prune_empty,
        log_file=log_file,
        make_rollback=not args.no_rollback,
        verbose=args.verbose,
    )

    print(f"[{_ts()}] é˜¶æ®µ6/6ï¼šéªŒè¯ä¸æŠ¥å‘Šâ€¦")
    _summarize(root, rules, actions, counts, dry_run=dry_run, log_file=log_file)
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))
