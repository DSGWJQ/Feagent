"""é˜¶æ®µ2æµ‹è¯•ï¼šä¸Šä¸‹æ–‡å‹ç¼©ä¸ä¼ é€’ - å…«æ®µå‹ç¼©æ¨¡å—

æµ‹è¯•ç›®æ ‡ï¼š
1. å®ç°"å…«æ®µå‹ç¼©"æ¨¡å—ï¼Œå°†å¤æ‚å¯¹è¯/æ‰§è¡Œæ—¥å¿—å‹ç¼©æˆç»“æ„åŒ–æ‘˜è¦
2. éªŒè¯å…«æ®µç»“æ„çš„å®Œæ•´æ€§å’Œæ•°æ®ä¸€è‡´æ€§
3. æµ‹è¯• Coordinator è°ƒç”¨å‹ç¼©å™¨æ›´æ–°ä¸Šä¸‹æ–‡å¿«ç…§çš„æµç¨‹

å…«æ®µç»“æ„å®šä¹‰ï¼š
1. TaskGoal - ä»»åŠ¡ç›®æ ‡æ®µï¼šå½“å‰å·¥ä½œæµçš„ç›®æ ‡
2. ExecutionStatus - æ‰§è¡ŒçŠ¶æ€æ®µï¼šå½“å‰æ‰§è¡Œè¿›åº¦
3. NodeSummary - èŠ‚ç‚¹æ‘˜è¦æ®µï¼šå·²æ‰§è¡ŒèŠ‚ç‚¹çš„å…³é”®ä¿¡æ¯
4. DecisionHistory - å†³ç­–å†å²æ®µï¼šé‡è¦å†³ç­–è®°å½•
5. ReflectionSummary - åæ€ç»“æœæ®µï¼šåæ€çš„å…³é”®å‘ç°
6. ConversationSummary - å¯¹è¯æ‘˜è¦æ®µï¼šå¯¹è¯çš„æ ¸å¿ƒå†…å®¹
7. ErrorLog - é”™è¯¯è®°å½•æ®µï¼šå‘ç”Ÿçš„é”™è¯¯å’Œå¤„ç†æƒ…å†µ
8. NextActions - ä¸‹ä¸€æ­¥å»ºè®®æ®µï¼šæ¨èçš„åç»­è¡ŒåŠ¨

å®Œæˆæ ‡å‡†ï¼š
- å…«æ®µç»“æ„å®Œæ•´ï¼Œæ¯æ®µæœ‰æ˜ç¡®çš„æ•°æ®æ¨¡å‹
- å‹ç¼©å™¨èƒ½æ­£ç¡®å¤„ç†å„ç±»è¾“å…¥æ•°æ®
- Coordinator èƒ½æ­£ç¡®è°ƒç”¨å‹ç¼©å™¨å¹¶æ›´æ–°å¿«ç…§
- æ”¯æŒå¢é‡æ›´æ–°å’Œå…¨é‡é‡å»º
"""

from datetime import datetime

import pytest

# ==================== æµ‹è¯•1ï¼šå…«æ®µå‹ç¼©æ•°æ®ç»“æ„ ====================


class TestEightSegmentDataStructures:
    """æµ‹è¯•å…«æ®µå‹ç¼©çš„æ•°æ®ç»“æ„"""

    def test_compressed_context_has_eight_segments(self):
        """å‹ç¼©ä¸Šä¸‹æ–‡åº”åŒ…å«å®Œæ•´çš„å…«ä¸ªæ®µè½"""
        from src.domain.services.context_compressor import CompressedContext

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="åˆ›å»ºæ•°æ®åˆ†æå·¥ä½œæµ",
            execution_status={"status": "running", "progress": 0.5},
            node_summary=[{"node_id": "n1", "summary": "LLMåˆ†æå®Œæˆ"}],
            decision_history=[{"decision": "ä½¿ç”¨GPT-4", "reason": "æ›´å‡†ç¡®"}],
            reflection_summary={"assessment": "æ‰§è¡Œé¡ºåˆ©", "confidence": 0.9},
            conversation_summary="ç”¨æˆ·è¦æ±‚åˆ†æé”€å”®æ•°æ®",
            error_log=[],
            next_actions=["æ‰§è¡Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹", "éªŒè¯ç»“æœ"],
        )

        # éªŒè¯å…«æ®µéƒ½å­˜åœ¨
        assert context.task_goal is not None
        assert context.execution_status is not None
        assert context.node_summary is not None
        assert context.decision_history is not None
        assert context.reflection_summary is not None
        assert context.conversation_summary is not None
        assert context.error_log is not None
        assert context.next_actions is not None

    def test_compressed_context_has_metadata(self):
        """å‹ç¼©ä¸Šä¸‹æ–‡åº”åŒ…å«å…ƒæ•°æ®ï¼šworkflow_id, created_at, version"""
        from src.domain.services.context_compressor import CompressedContext

        context = CompressedContext(workflow_id="wf_001")

        assert context.workflow_id == "wf_001"
        assert context.created_at is not None
        assert isinstance(context.created_at, datetime)
        assert context.version >= 1

    def test_segment_types_are_correct(self):
        """å„æ®µçš„æ•°æ®ç±»å‹åº”æ­£ç¡®"""
        from src.domain.services.context_compressor import CompressedContext

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="ç›®æ ‡æè¿°",
            execution_status={"status": "running"},
            node_summary=[{"node_id": "n1"}],
            decision_history=[{"decision": "d1"}],
            reflection_summary={"assessment": "è‰¯å¥½"},
            conversation_summary="å¯¹è¯æ‘˜è¦",
            error_log=[{"error": "e1"}],
            next_actions=["action1", "action2"],
        )

        # ç±»å‹æ£€æŸ¥
        assert isinstance(context.task_goal, str)
        assert isinstance(context.execution_status, dict)
        assert isinstance(context.node_summary, list)
        assert isinstance(context.decision_history, list)
        assert isinstance(context.reflection_summary, dict)
        assert isinstance(context.conversation_summary, str)
        assert isinstance(context.error_log, list)
        assert isinstance(context.next_actions, list)


# ==================== æµ‹è¯•2ï¼šå‹ç¼©è¾“å…¥æ•°æ®ç»“æ„ ====================


class TestCompressionInputStructures:
    """æµ‹è¯•å‹ç¼©è¾“å…¥çš„æ•°æ®ç»“æ„"""

    def test_compression_input_from_conversation_log(self):
        """å‹ç¼©è¾“å…¥ï¼šä»å¯¹è¯æ—¥å¿—åˆ›å»º"""
        from src.domain.services.context_compressor import CompressionInput

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [
                    {"role": "user", "content": "åˆ†æé”€å”®æ•°æ®"},
                    {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘æ¥åˆ†æ"},
                ],
                "session_id": "session_123",
            },
        )

        assert input_data.source_type == "conversation"
        assert input_data.workflow_id == "wf_001"
        assert "messages" in input_data.raw_data

    def test_compression_input_from_execution_log(self):
        """å‹ç¼©è¾“å…¥ï¼šä»æ‰§è¡Œæ—¥å¿—åˆ›å»º"""
        from src.domain.services.context_compressor import CompressionInput

        input_data = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "nodes_executed": ["n1", "n2"],
                "node_outputs": {
                    "n1": {"result": "success"},
                    "n2": {"result": "pending"},
                },
                "errors": [],
            },
        )

        assert input_data.source_type == "execution"
        assert "nodes_executed" in input_data.raw_data

    def test_compression_input_from_reflection(self):
        """å‹ç¼©è¾“å…¥ï¼šä»åæ€ç»“æœåˆ›å»º"""
        from src.domain.services.context_compressor import CompressionInput

        input_data = CompressionInput(
            source_type="reflection",
            workflow_id="wf_001",
            raw_data={
                "assessment": "æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç°æ•°æ®æ ¼å¼é—®é¢˜",
                "issues": ["æ•°æ®æ ¼å¼ä¸ä¸€è‡´"],
                "recommendations": ["æ·»åŠ æ•°æ®æ ¡éªŒèŠ‚ç‚¹"],
                "confidence": 0.85,
                "should_retry": False,
            },
        )

        assert input_data.source_type == "reflection"
        assert input_data.raw_data["confidence"] == 0.85


# ==================== æµ‹è¯•3ï¼šä¸Šä¸‹æ–‡å‹ç¼©å™¨æ ¸å¿ƒåŠŸèƒ½ ====================


class TestContextCompressorCore:
    """æµ‹è¯•ä¸Šä¸‹æ–‡å‹ç¼©å™¨æ ¸å¿ƒåŠŸèƒ½"""

    def test_compress_empty_input_returns_minimal_context(self):
        """å‹ç¼©ç©ºè¾“å…¥åº”è¿”å›æœ€å°ä¸Šä¸‹æ–‡"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={},
        )

        result = compressor.compress(input_data)

        assert result.workflow_id == "wf_001"
        assert result.task_goal == ""
        assert result.execution_status == {}
        assert result.node_summary == []
        assert result.error_log == []

    def test_compress_conversation_extracts_goal(self):
        """å‹ç¼©å¯¹è¯æ—¥å¿—åº”æå–ä»»åŠ¡ç›®æ ‡"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [
                    {"role": "user", "content": "å¸®æˆ‘åˆ›å»ºä¸€ä¸ªåˆ†æé”€å”®æ•°æ®çš„å·¥ä½œæµ"},
                    {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘æ¥ä¸ºæ‚¨åˆ›å»º"},
                ],
                "intent": "CREATE_WORKFLOW",
                "goal": "åˆ›å»ºåˆ†æé”€å”®æ•°æ®çš„å·¥ä½œæµ",
            },
        )

        result = compressor.compress(input_data)

        assert "é”€å”®æ•°æ®" in result.task_goal or "åˆ›å»º" in result.task_goal
        assert result.conversation_summary != ""

    def test_compress_execution_log_extracts_node_summary(self):
        """å‹ç¼©æ‰§è¡Œæ—¥å¿—åº”æå–èŠ‚ç‚¹æ‘˜è¦"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [
                    {
                        "node_id": "node_1",
                        "type": "LLM",
                        "status": "completed",
                        "output": {"content": "åˆ†æç»“æœ..."},
                    },
                    {
                        "node_id": "node_2",
                        "type": "HTTP",
                        "status": "running",
                        "output": None,
                    },
                ],
                "workflow_status": "running",
                "progress": 0.5,
            },
        )

        result = compressor.compress(input_data)

        assert len(result.node_summary) == 2
        assert result.execution_status.get("status") == "running"
        assert result.execution_status.get("progress") == 0.5

    def test_compress_execution_log_extracts_errors(self):
        """å‹ç¼©æ‰§è¡Œæ—¥å¿—åº”æå–é”™è¯¯ä¿¡æ¯"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [
                    {
                        "node_id": "node_1",
                        "type": "HTTP",
                        "status": "failed",
                        "error": "Connection timeout",
                    },
                ],
                "workflow_status": "failed",
                "errors": [{"node_id": "node_1", "error": "Connection timeout", "retryable": True}],
            },
        )

        result = compressor.compress(input_data)

        assert len(result.error_log) >= 1
        assert any("timeout" in str(e).lower() for e in result.error_log)

    def test_compress_reflection_extracts_assessment(self):
        """å‹ç¼©åæ€ç»“æœåº”æå–è¯„ä¼°ä¿¡æ¯"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="reflection",
            workflow_id="wf_001",
            raw_data={
                "assessment": "å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼Œä½†å¯ä¼˜åŒ–æ•°æ®å¤„ç†æµç¨‹",
                "issues": ["æ•°æ®å¤„ç†è€—æ—¶è¾ƒé•¿"],
                "recommendations": ["æ·»åŠ ç¼“å­˜èŠ‚ç‚¹", "å¹¶è¡Œå¤„ç†"],
                "confidence": 0.92,
                "should_retry": False,
            },
        )

        result = compressor.compress(input_data)

        assert "assessment" in result.reflection_summary
        assert result.reflection_summary["confidence"] == 0.92
        assert len(result.next_actions) >= 1


# ==================== æµ‹è¯•4ï¼šå¢é‡å‹ç¼©åŠŸèƒ½ ====================


class TestIncrementalCompression:
    """æµ‹è¯•å¢é‡å‹ç¼©åŠŸèƒ½"""

    def test_merge_new_input_into_existing_context(self):
        """åˆå¹¶æ–°è¾“å…¥åˆ°ç°æœ‰ä¸Šä¸‹æ–‡"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        # ç°æœ‰ä¸Šä¸‹æ–‡
        existing = CompressedContext(
            workflow_id="wf_001",
            task_goal="åˆ›å»ºæ•°æ®åˆ†æå·¥ä½œæµ",
            execution_status={"status": "running", "progress": 0.3},
            node_summary=[{"node_id": "n1", "status": "completed"}],
            decision_history=[],
            reflection_summary={},
            conversation_summary="ç”¨æˆ·è¯·æ±‚åˆ†æé”€å”®æ•°æ®",
            error_log=[],
            next_actions=["æ‰§è¡ŒèŠ‚ç‚¹2"],
        )

        # æ–°è¾“å…¥
        new_input = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [
                    {"node_id": "n2", "status": "completed", "output": {"result": "ok"}},
                ],
                "workflow_status": "running",
                "progress": 0.6,
            },
        )

        result = compressor.merge(existing, new_input)

        # éªŒè¯åˆå¹¶ç»“æœ
        assert result.workflow_id == "wf_001"
        assert result.execution_status.get("progress") == 0.6  # æ›´æ–°è¿›åº¦
        assert len(result.node_summary) == 2  # å¢åŠ äº†èŠ‚ç‚¹
        assert result.task_goal == "åˆ›å»ºæ•°æ®åˆ†æå·¥ä½œæµ"  # ä¿æŒä¸å˜

    def test_merge_updates_version(self):
        """åˆå¹¶æ—¶åº”æ›´æ–°ç‰ˆæœ¬å·"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        existing = CompressedContext(workflow_id="wf_001", version=1)

        new_input = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={"progress": 0.5},
        )

        result = compressor.merge(existing, new_input)

        assert result.version == 2

    def test_merge_preserves_error_log(self):
        """åˆå¹¶æ—¶åº”ä¿ç•™é”™è¯¯æ—¥å¿—"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        existing = CompressedContext(
            workflow_id="wf_001",
            error_log=[{"node_id": "n1", "error": "Error 1"}],
        )

        new_input = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "errors": [{"node_id": "n2", "error": "Error 2"}],
            },
        )

        result = compressor.merge(existing, new_input)

        assert len(result.error_log) == 2

    def test_merge_updates_reflection_summary(self):
        """åˆå¹¶åæ€ç»“æœåº”æ›´æ–°åæ€æ‘˜è¦"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        existing = CompressedContext(
            workflow_id="wf_001",
            reflection_summary={"assessment": "åˆæ­¥è¯„ä¼°", "confidence": 0.7},
        )

        new_input = CompressionInput(
            source_type="reflection",
            workflow_id="wf_001",
            raw_data={
                "assessment": "æœ€ç»ˆè¯„ä¼°ï¼šæ‰§è¡ŒæˆåŠŸ",
                "confidence": 0.95,
                "recommendations": ["ä¼˜åŒ–ç¼“å­˜"],
            },
        )

        result = compressor.merge(existing, new_input)

        assert result.reflection_summary["confidence"] == 0.95
        assert "æœ€ç»ˆè¯„ä¼°" in result.reflection_summary["assessment"]


# ==================== æµ‹è¯•5ï¼šä¸Šä¸‹æ–‡å¿«ç…§ç®¡ç† ====================


class TestContextSnapshotManagement:
    """æµ‹è¯•ä¸Šä¸‹æ–‡å¿«ç…§ç®¡ç†"""

    def test_create_snapshot_from_context(self):
        """ä»ä¸Šä¸‹æ–‡åˆ›å»ºå¿«ç…§"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            ContextSnapshotManager,
        )

        manager = ContextSnapshotManager()

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="æµ‹è¯•ç›®æ ‡",
            execution_status={"status": "running"},
        )

        snapshot_id = manager.save_snapshot(context)

        assert snapshot_id is not None
        assert snapshot_id.startswith("snap_")

    def test_retrieve_snapshot_by_id(self):
        """é€šè¿‡IDæ£€ç´¢å¿«ç…§"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            ContextSnapshotManager,
        )

        manager = ContextSnapshotManager()

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="æµ‹è¯•ç›®æ ‡",
        )

        snapshot_id = manager.save_snapshot(context)
        retrieved = manager.get_snapshot(snapshot_id)

        assert retrieved is not None
        assert retrieved.workflow_id == "wf_001"
        assert retrieved.task_goal == "æµ‹è¯•ç›®æ ‡"

    def test_list_snapshots_by_workflow(self):
        """æŒ‰å·¥ä½œæµåˆ—å‡ºå¿«ç…§"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            ContextSnapshotManager,
        )

        manager = ContextSnapshotManager()

        # ä¸ºåŒä¸€å·¥ä½œæµåˆ›å»ºå¤šä¸ªå¿«ç…§
        for i in range(3):
            context = CompressedContext(
                workflow_id="wf_001",
                task_goal=f"ç›®æ ‡_{i}",
                version=i + 1,
            )
            manager.save_snapshot(context)

        # ä¸ºå¦ä¸€ä¸ªå·¥ä½œæµåˆ›å»ºå¿«ç…§
        other_context = CompressedContext(workflow_id="wf_002")
        manager.save_snapshot(other_context)

        snapshots = manager.list_snapshots(workflow_id="wf_001")

        assert len(snapshots) == 3

    def test_get_latest_snapshot(self):
        """è·å–æœ€æ–°å¿«ç…§"""
        from src.domain.services.context_compressor import (
            CompressedContext,
            ContextSnapshotManager,
        )

        manager = ContextSnapshotManager()

        # åˆ›å»ºå¤šä¸ªç‰ˆæœ¬
        for i in range(3):
            context = CompressedContext(
                workflow_id="wf_001",
                task_goal=f"ç›®æ ‡_{i}",
                version=i + 1,
            )
            manager.save_snapshot(context)

        latest = manager.get_latest_snapshot(workflow_id="wf_001")

        assert latest is not None
        assert latest.version == 3
        assert latest.task_goal == "ç›®æ ‡_2"


# ==================== æµ‹è¯•6ï¼šå…«æ®µå‹ç¼©ç­–ç•¥ ====================


class TestEightSegmentCompressionStrategies:
    """æµ‹è¯•å…«æ®µå‹ç¼©çš„å„ç§ç­–ç•¥"""

    def test_task_goal_extraction_from_user_intent(self):
        """ä»ç”¨æˆ·æ„å›¾æå–ä»»åŠ¡ç›®æ ‡"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "intent": "CREATE_WORKFLOW",
            "confidence": 0.95,
            "entities": {
                "action": "åˆ›å»º",
                "target": "é”€å”®åˆ†æå·¥ä½œæµ",
            },
            "messages": [{"role": "user", "content": "å¸®æˆ‘åˆ›å»ºé”€å”®åˆ†æå·¥ä½œæµ"}],
        }

        goal = compressor._extract_task_goal(raw_data)

        assert "é”€å”®" in goal or "å·¥ä½œæµ" in goal

    def test_execution_status_summarization(self):
        """æ‰§è¡ŒçŠ¶æ€æ‘˜è¦"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "workflow_status": "running",
            "progress": 0.75,
            "started_at": "2024-01-01T10:00:00",
            "estimated_completion": "2024-01-01T10:05:00",
            "nodes_total": 4,
            "nodes_completed": 3,
        }

        status = compressor._extract_execution_status(raw_data)

        assert status["status"] == "running"
        assert status["progress"] == 0.75
        assert "nodes_completed" in status

    def test_node_summary_compression(self):
        """èŠ‚ç‚¹æ‘˜è¦å‹ç¼©"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "executed_nodes": [
                {
                    "node_id": "llm_1",
                    "type": "LLM",
                    "status": "completed",
                    "started_at": "2024-01-01T10:00:00",
                    "completed_at": "2024-01-01T10:00:30",
                    "output": {
                        "content": "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„LLMè¾“å‡ºå†…å®¹ï¼ŒåŒ…å«è¯¦ç»†åˆ†æ..." * 10,
                        "tokens_used": 1500,
                    },
                },
            ]
        }

        summaries = compressor._extract_node_summaries(raw_data)

        assert len(summaries) == 1
        assert summaries[0]["node_id"] == "llm_1"
        assert summaries[0]["status"] == "completed"
        # è¾“å‡ºåº”è¢«å‹ç¼©ï¼Œä¸åŒ…å«å®Œæ•´å†…å®¹
        assert len(str(summaries[0].get("output_summary", ""))) < 200

    def test_decision_history_extraction(self):
        """å†³ç­–å†å²æå–"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "decisions": [
                {
                    "decision_type": "node_selection",
                    "choice": "GPT-4",
                    "reason": "éœ€è¦æ›´é«˜çš„å‡†ç¡®æ€§",
                    "alternatives": ["GPT-3.5", "Claude"],
                    "timestamp": "2024-01-01T10:00:00",
                },
                {
                    "decision_type": "retry_strategy",
                    "choice": "exponential_backoff",
                    "reason": "é¿å…é¢‘ç¹è¯·æ±‚",
                },
            ]
        }

        history = compressor._extract_decision_history(raw_data)

        assert len(history) == 2
        assert history[0]["decision_type"] == "node_selection"

    def test_conversation_summary_compression(self):
        """å¯¹è¯æ‘˜è¦å‹ç¼©"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "messages": [
                {"role": "user", "content": "æˆ‘éœ€è¦åˆ†æä¸Šä¸ªæœˆçš„é”€å”®æ•°æ®"},
                {"role": "assistant", "content": "å¥½çš„ï¼Œè¯·é—®æ‚¨éœ€è¦åˆ†æå“ªäº›ç»´åº¦ï¼Ÿ"},
                {"role": "user", "content": "æŒ‰äº§å“ç±»åˆ«å’Œåœ°åŒºåˆ†æ"},
                {
                    "role": "assistant",
                    "content": "æ˜ç™½äº†ï¼Œæˆ‘å°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåŒ…å«æ•°æ®è·å–ã€åˆ†æå’Œå¯è§†åŒ–çš„å·¥ä½œæµ",
                },
            ]
        }

        summary = compressor._extract_conversation_summary(raw_data)

        # æ‘˜è¦åº”è¯¥ç®€æ´ä½†åŒ…å«å…³é”®ä¿¡æ¯
        assert len(summary) > 0
        assert len(summary) < 500  # ä¸åº”è¿‡é•¿
        # åº”åŒ…å«å…³é”®è¯
        assert "é”€å”®" in summary or "åˆ†æ" in summary

    def test_next_actions_generation(self):
        """ä¸‹ä¸€æ­¥è¡ŒåŠ¨å»ºè®®ç”Ÿæˆ"""
        from src.domain.services.context_compressor import ContextCompressor

        compressor = ContextCompressor()

        raw_data = {
            "workflow_status": "running",
            "current_node": "node_2",
            "pending_nodes": ["node_3", "node_4"],
            "reflection": {
                "recommendations": ["ä¼˜åŒ–æ•°æ®ç¼“å­˜", "æ·»åŠ é”™è¯¯å¤„ç†"],
            },
        }

        actions = compressor._extract_next_actions(raw_data)

        assert len(actions) >= 1
        # åº”åŒ…å«å¾…æ‰§è¡ŒèŠ‚ç‚¹æˆ–å»ºè®®
        assert any("node" in a.lower() or "æ‰§è¡Œ" in a for a in actions) or any(
            "ä¼˜åŒ–" in a or "æ·»åŠ " in a for a in actions
        )


# ==================== æµ‹è¯•7ï¼šä¸ç°æœ‰æ‘˜è¦ç³»ç»Ÿé›†æˆ ====================


class TestIntegrationWithSummarySystem:
    """æµ‹è¯•ä¸ç°æœ‰æ‘˜è¦ç³»ç»Ÿçš„é›†æˆ"""

    def test_use_evidence_store_for_raw_data(self):
        """ä½¿ç”¨è¯æ®å­˜å‚¨ä¿å­˜åŸå§‹æ•°æ®"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )
        from src.domain.services.summary_strategy import EvidenceStore

        evidence_store = EvidenceStore()
        compressor = ContextCompressor(evidence_store=evidence_store)

        input_data = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [{"node_id": "n1", "output": {"result": "detailed data"}}],
            },
        )

        result = compressor.compress(input_data)

        # åº”è¯¥æœ‰è¯æ®å¼•ç”¨
        assert len(result.evidence_refs) > 0
        # å¯ä»¥é€šè¿‡å¼•ç”¨æ£€ç´¢åŸå§‹æ•°æ®
        for ref_id in result.evidence_refs:
            data = evidence_store.retrieve(ref_id)
            assert data is not None

    def test_compressed_context_has_summary_info_compatibility(self):
        """å‹ç¼©ä¸Šä¸‹æ–‡ä¸ SummaryInfo å…¼å®¹"""
        from src.domain.services.context_compressor import CompressedContext
        from src.domain.services.summary_strategy import SummaryInfo

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="æµ‹è¯•ç›®æ ‡",
            evidence_refs=["ref_001", "ref_002"],
        )

        # å¯ä»¥è½¬æ¢ä¸º SummaryInfo
        summary_info = SummaryInfo(
            summary=context.to_summary_text(),
            evidence_refs=context.evidence_refs,
            source_id=context.workflow_id,
        )

        assert summary_info.summary is not None
        assert len(summary_info.evidence_refs) == 2


# ==================== æµ‹è¯•8ï¼šçœŸå®åœºæ™¯æµ‹è¯• ====================


class TestRealWorldScenarios:
    """çœŸå®åœºæ™¯æµ‹è¯•"""

    def test_full_workflow_compression_flow(self):
        """å®Œæ•´çš„å·¥ä½œæµå‹ç¼©æµç¨‹"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
            ContextSnapshotManager,
        )

        compressor = ContextCompressor()
        snapshot_manager = ContextSnapshotManager()

        # 1. åˆå§‹å¯¹è¯
        conversation_input = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [
                    {"role": "user", "content": "åˆ†ææœ€è¿‘çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®"},
                ],
                "goal": "åˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®",
            },
        )
        ctx1 = compressor.compress(conversation_input)
        snapshot_manager.save_snapshot(ctx1)

        # 2. æ‰§è¡Œè¿›åº¦æ›´æ–°
        execution_input = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [
                    {"node_id": "fetch", "status": "completed"},
                    {"node_id": "analyze", "status": "running"},
                ],
                "workflow_status": "running",
                "progress": 0.5,
            },
        )
        ctx2 = compressor.merge(ctx1, execution_input)
        snapshot_manager.save_snapshot(ctx2)

        # 3. åæ€ç»“æœ
        reflection_input = CompressionInput(
            source_type="reflection",
            workflow_id="wf_001",
            raw_data={
                "assessment": "æ•°æ®åˆ†æèŠ‚ç‚¹æ‰§è¡Œæ—¶é—´è¿‡é•¿",
                "recommendations": ["å¢åŠ å¹¶è¡Œå¤„ç†", "ä¼˜åŒ–æŸ¥è¯¢"],
                "confidence": 0.85,
            },
        )
        ctx3 = compressor.merge(ctx2, reflection_input)
        snapshot_manager.save_snapshot(ctx3)

        # éªŒè¯æœ€ç»ˆå‹ç¼©ç»“æœ
        final = snapshot_manager.get_latest_snapshot("wf_001")

        assert final.task_goal != ""
        assert final.execution_status.get("progress") == 0.5
        assert len(final.node_summary) == 2
        assert final.reflection_summary.get("confidence") == 0.85
        assert len(final.next_actions) >= 1

    def test_error_recovery_compression(self):
        """é”™è¯¯æ¢å¤åœºæ™¯çš„å‹ç¼©"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        # åˆå§‹ä¸Šä¸‹æ–‡
        initial = compressor.compress(
            CompressionInput(
                source_type="execution",
                workflow_id="wf_001",
                raw_data={
                    "executed_nodes": [
                        {"node_id": "n1", "status": "completed"},
                        {"node_id": "n2", "status": "failed", "error": "API timeout"},
                    ],
                    "workflow_status": "failed",
                    "errors": [{"node_id": "n2", "error": "API timeout", "retryable": True}],
                },
            )
        )

        # é‡è¯•åçš„æ›´æ–°
        retry_input = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "executed_nodes": [{"node_id": "n2", "status": "completed", "retry_count": 1}],
                "workflow_status": "running",
            },
        )

        recovered = compressor.merge(initial, retry_input)

        # é”™è¯¯æ—¥å¿—åº”ä¿ç•™å†å²
        assert len(recovered.error_log) >= 1
        # èŠ‚ç‚¹çŠ¶æ€åº”æ›´æ–°
        node_n2 = next((n for n in recovered.node_summary if n["node_id"] == "n2"), None)
        assert node_n2 is not None
        assert node_n2["status"] == "completed"

    @pytest.mark.asyncio
    async def test_coordinator_integration_simulation(self):
        """æ¨¡æ‹Ÿ Coordinator é›†æˆåœºæ™¯"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
            ContextSnapshotManager,
        )

        # æ¨¡æ‹Ÿ Coordinator ä½¿ç”¨å‹ç¼©å™¨
        class MockCoordinator:
            def __init__(self):
                self.compressor = ContextCompressor()
                self.snapshot_manager = ContextSnapshotManager()
                self.current_context: dict = {}

            def on_reflection_completed(self, workflow_id: str, reflection_data: dict):
                """å¤„ç†åæ€å®Œæˆäº‹ä»¶"""
                input_data = CompressionInput(
                    source_type="reflection",
                    workflow_id=workflow_id,
                    raw_data=reflection_data,
                )

                if workflow_id in self.current_context:
                    new_ctx = self.compressor.merge(self.current_context[workflow_id], input_data)
                else:
                    new_ctx = self.compressor.compress(input_data)

                self.current_context[workflow_id] = new_ctx
                self.snapshot_manager.save_snapshot(new_ctx)

                return new_ctx

            def get_context_for_conversation_agent(self, workflow_id: str):
                """è·å–å¯¹è¯Agentå¯è§çš„ä¸Šä¸‹æ–‡"""
                return self.current_context.get(workflow_id)

        coordinator = MockCoordinator()

        # æ¨¡æ‹Ÿåæ€äº‹ä»¶
        reflection_data = {
            "assessment": "å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
            "confidence": 0.95,
            "recommendations": ["å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œ"],
        }

        ctx = coordinator.on_reflection_completed("wf_001", reflection_data)

        assert ctx is not None
        assert ctx.reflection_summary["confidence"] == 0.95

        # å¯¹è¯Agentå¯ä»¥è·å–ä¸Šä¸‹æ–‡
        visible_ctx = coordinator.get_context_for_conversation_agent("wf_001")
        assert visible_ctx is not None


# ==================== æµ‹è¯•9ï¼šè¾¹ç•Œæƒ…å†µ ====================


class TestEdgeCases:
    """è¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    def test_compress_with_missing_fields(self):
        """å¤„ç†ç¼ºå¤±å­—æ®µçš„è¾“å…¥"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        # åªæœ‰éƒ¨åˆ†å­—æ®µ
        input_data = CompressionInput(
            source_type="execution",
            workflow_id="wf_001",
            raw_data={
                "workflow_status": "running",
                # ç¼ºå°‘ executed_nodes, progress ç­‰
            },
        )

        result = compressor.compress(input_data)

        # ä¸åº”æŠ›å‡ºå¼‚å¸¸
        assert result.workflow_id == "wf_001"
        assert result.execution_status.get("status") == "running"

    def test_compress_with_very_long_content(self):
        """å¤„ç†è¶…é•¿å†…å®¹"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor(max_segment_length=200)

        long_content = "è¿™æ˜¯ä¸€æ®µéå¸¸é•¿çš„å†…å®¹ã€‚" * 1000

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [{"role": "assistant", "content": long_content}],
            },
        )

        result = compressor.compress(input_data)

        # æ‘˜è¦åº”è¢«æˆªæ–­
        assert len(result.conversation_summary) <= 200

    def test_compress_with_special_characters(self):
        """å¤„ç†ç‰¹æ®Šå­—ç¬¦"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [
                    {
                        "role": "user",
                        "content": "åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š<script>alert('xss')</script> & ' \" \n\t",
                    }
                ],
            },
        )

        # ä¸åº”æŠ›å‡ºå¼‚å¸¸
        result = compressor.compress(input_data)
        assert result is not None

    def test_compress_with_unicode(self):
        """å¤„ç† Unicode å­—ç¬¦"""
        from src.domain.services.context_compressor import (
            CompressionInput,
            ContextCompressor,
        )

        compressor = ContextCompressor()

        input_data = CompressionInput(
            source_type="conversation",
            workflow_id="wf_001",
            raw_data={
                "messages": [
                    {"role": "user", "content": "ä¸­æ–‡æ¶ˆæ¯ ğŸ‰ æ—¥æœ¬èª í•œêµ­ì–´ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"},
                ],
            },
        )

        result = compressor.compress(input_data)
        assert result is not None
        assert "ä¸­æ–‡" in result.conversation_summary or len(result.conversation_summary) > 0

    def test_concurrent_snapshot_access(self):
        """å¹¶å‘å¿«ç…§è®¿é—®"""
        import asyncio

        from src.domain.services.context_compressor import (
            CompressedContext,
            ContextSnapshotManager,
        )

        manager = ContextSnapshotManager()

        async def save_and_retrieve(i):
            context = CompressedContext(
                workflow_id=f"wf_{i % 3}",  # 3ä¸ªä¸åŒçš„å·¥ä½œæµ
                task_goal=f"ç›®æ ‡_{i}",
                version=i,
            )
            snapshot_id = manager.save_snapshot(context)
            retrieved = manager.get_snapshot(snapshot_id)
            assert retrieved.task_goal == f"ç›®æ ‡_{i}"
            return snapshot_id

        async def run_concurrent():
            tasks = [save_and_retrieve(i) for i in range(50)]
            results = await asyncio.gather(*tasks)
            assert len(results) == 50
            assert len(set(results)) == 50  # æ‰€æœ‰IDå”¯ä¸€

        asyncio.run(run_concurrent())


# ==================== æµ‹è¯•10ï¼šè½¬æ¢å’Œåºåˆ—åŒ– ====================


class TestSerializationAndConversion:
    """æµ‹è¯•åºåˆ—åŒ–å’Œè½¬æ¢"""

    def test_compressed_context_to_dict(self):
        """å‹ç¼©ä¸Šä¸‹æ–‡è½¬æ¢ä¸ºå­—å…¸"""
        from src.domain.services.context_compressor import CompressedContext

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="æµ‹è¯•ç›®æ ‡",
            execution_status={"status": "running"},
            node_summary=[{"node_id": "n1"}],
            decision_history=[],
            reflection_summary={},
            conversation_summary="å¯¹è¯æ‘˜è¦",
            error_log=[],
            next_actions=["action1"],
        )

        result = context.to_dict()

        assert isinstance(result, dict)
        assert result["workflow_id"] == "wf_001"
        assert result["task_goal"] == "æµ‹è¯•ç›®æ ‡"
        assert "created_at" in result

    def test_compressed_context_from_dict(self):
        """ä»å­—å…¸åˆ›å»ºå‹ç¼©ä¸Šä¸‹æ–‡"""
        from src.domain.services.context_compressor import CompressedContext

        data = {
            "workflow_id": "wf_001",
            "task_goal": "æµ‹è¯•ç›®æ ‡",
            "execution_status": {"status": "completed"},
            "node_summary": [],
            "decision_history": [],
            "reflection_summary": {},
            "conversation_summary": "",
            "error_log": [],
            "next_actions": [],
            "version": 3,
        }

        context = CompressedContext.from_dict(data)

        assert context.workflow_id == "wf_001"
        assert context.version == 3

    def test_to_summary_text(self):
        """ç”Ÿæˆæ‘˜è¦æ–‡æœ¬"""
        from src.domain.services.context_compressor import CompressedContext

        context = CompressedContext(
            workflow_id="wf_001",
            task_goal="åˆ†æé”€å”®æ•°æ®",
            execution_status={"status": "running", "progress": 0.5},
            node_summary=[{"node_id": "n1", "status": "completed"}],
            reflection_summary={"assessment": "è¿›å±•é¡ºåˆ©"},
            conversation_summary="ç”¨æˆ·è¯·æ±‚åˆ†ææ•°æ®",
            next_actions=["æ‰§è¡Œä¸‹ä¸€èŠ‚ç‚¹"],
        )

        text = context.to_summary_text()

        assert isinstance(text, str)
        assert len(text) > 0
        # åº”åŒ…å«å…³é”®ä¿¡æ¯
        assert "åˆ†æé”€å”®æ•°æ®" in text or "é”€å”®" in text
